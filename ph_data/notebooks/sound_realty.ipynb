{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c87de31-1476-40be-bef2-7ef96a412d3f",
   "metadata": {},
   "source": [
    "# Predicting real estate prices - Model serving and deployment\n",
    "\n",
    "## Background\n",
    "Sound Realty helps people sell homes in the Seattle area.\n",
    "\n",
    "They currently spend too much time and effort on estimating the value of properties.\n",
    "\n",
    "One of their staff has heard a lot about machine learning (ML) and has created a basic model to estimate the value of properties.\n",
    "\n",
    "The basic model uses only numeric variables and ignores some other attributes.\n",
    "Despite the simplicity of this model, the folks at Sound are impressed with the proof of concept and would now like to use this model to streamline\n",
    "their business.\n",
    "\n",
    "They have contracted us to help deploy that model for broader use.\n",
    "Our job is to create a REST endpoint that serves up model predictions for new data, and to provide guidance on how they could improve the model.\n",
    "\n",
    "## Proposed Solution\n",
    "\n",
    "Here I shall deploy the model to a REST endpoint using Modal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f5117f-629a-4327-bba8-74893cb2ec2d",
   "metadata": {},
   "source": [
    "## Library Installation and Import\n",
    "\n",
    "Below I shall install then import the libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39717c7d-d6a3-4ea6-a03f-a6d441a47ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting uv\n",
      "  Downloading uv-0.8.19-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Downloading uv-0.8.19-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: uv\n",
      "Successfully installed uv-0.8.19\n"
     ]
    }
   ],
   "source": [
    "!pip install uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8682ccf3-9271-4aca-ae74-c57dbdd3d665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%pip install seaborn tqdm sweetviz dash streamlit plotly requests gradio joblib scikit-learn ipywidgets modal bentoml wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "426b164c-146e-4aa8-964b-4c2e46bfd6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.10.12 environment at: /usr\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m96 packages\u001b[0m \u001b[2min 2.68s\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m6 packages\u001b[0m \u001b[2min 24.58s\u001b[0m\u001b[0m                                            \n",
      "\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: Failed to install: pyparsing-3.2.5-py3-none-any.whl (pyparsing==3.2.5)\n",
      "  \u001b[1m\u001b[31mCaused by\u001b[39m\u001b[0m: failed to create directory `/usr/local/lib/python3.10/dist-packages/pyparsing-3.2.5.dist-info`: Permission denied (os error 13)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[2mUsing Python 3.10.12 environment at: /usr\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m117 packages\u001b[0m \u001b[2min 2.09s\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m5 packages\u001b[0m \u001b[2min 3.45s\u001b[0m\u001b[0m                                             \n",
      "\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: Failed to install: threadpoolctl-3.6.0-py3-none-any.whl (threadpoolctl==3.6.0)\n",
      "  \u001b[1m\u001b[31mCaused by\u001b[39m\u001b[0m: failed to create directory `/usr/local/lib/python3.10/dist-packages/threadpoolctl-3.6.0.dist-info`: Permission denied (os error 13)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install seaborn tqdm sweetviz dash streamlit plotly requests gradio\n",
    "%uv pip install joblib scikit-learn ipywidgets modal bentoml wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999a2b63-44ae-4abd-94fe-6fb7875fb81c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a581158-7302-46ac-a897-aa03f1a862cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, matplotlib.pyplot as plt, seaborn as sns, numpy as np\n",
    "from numpy import random\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import interact\n",
    "from pathlib import Path\n",
    "import os, warnings, io, getpass, json, dash, modal, bentoml, gc, wandb, pickle\n",
    "from joblib import dump, load\n",
    "from dash import dcc, html, dash_table\n",
    "import typing as t\n",
    "from bentoml.validators import DataframeSchema\n",
    "from fastapi import File, UploadFile, Form, HTTPException\n",
    "import io\n",
    "np.set_printoptions(linewidth=130)\n",
    "plt.rc('image', cmap='Greys')\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3871fd93-1f47-44b9-a67e-0b9f52999715",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "We have 3 datasets namely\n",
    "- **kc_house_data.csv** – Data for training the model\n",
    "- **zipcode_demographics.csv** – Additional demographic data from the U.S. Census which are used as features. This data should be joined to the primary home sales using the zipcode column.\n",
    "- **future_unseen_examples.csv** – This file contains examples of homes to be sold in the future. It includes all attributes from the original home sales file, but not the price , date , or id . It also does not include the demographic data.\n",
    "\n",
    "\n",
    "Lets first take a look at our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e6c9f5-46c3-4ed2-835a-8ed84a15220b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('..')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('..')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1365a8-5c66-4013-a0a8-f927f3468410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "future_unseen_examples.csv  kc_house_data.csv  zipcode_demographics.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6f08a6c-52c7-41f5-9c81-c94f6762e684",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(path/'data/kc_house_data.csv', index_col='id')\n",
    "demographics_df = pd.read_csv(path/'data/zipcode_demographics.csv')\n",
    "test_df = pd.read_csv(path/'data/future_unseen_examples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b77223-785d-44ef-9e2d-ea3b7752b5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7129300520</th>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414100192</th>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631500400</th>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487200875</th>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954400510</th>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263000018</th>\n",
       "      <td>20140521T000000</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6600060120</th>\n",
       "      <td>20150223T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523300141</th>\n",
       "      <td>20140623T000000</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291310100</th>\n",
       "      <td>20150116T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523300157</th>\n",
       "      <td>20141015T000000</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "id                                                                        \n",
       "7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "...                     ...       ...       ...        ...          ...   \n",
       "263000018   20140521T000000  360000.0         3       2.50         1530   \n",
       "6600060120  20150223T000000  400000.0         4       2.50         2310   \n",
       "1523300141  20140623T000000  402101.0         2       0.75         1020   \n",
       "291310100   20150116T000000  400000.0         3       2.50         1600   \n",
       "1523300157  20141015T000000  325000.0         2       0.75         1020   \n",
       "\n",
       "            sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
       "id                                                                             \n",
       "7129300520      5650     1.0           0     0          3      7        1180   \n",
       "6414100192      7242     2.0           0     0          3      7        2170   \n",
       "5631500400     10000     1.0           0     0          3      6         770   \n",
       "2487200875      5000     1.0           0     0          5      7        1050   \n",
       "1954400510      8080     1.0           0     0          3      8        1680   \n",
       "...              ...     ...         ...   ...        ...    ...         ...   \n",
       "263000018       1131     3.0           0     0          3      8        1530   \n",
       "6600060120      5813     2.0           0     0          3      8        2310   \n",
       "1523300141      1350     2.0           0     0          3      7        1020   \n",
       "291310100       2388     2.0           0     0          3      8        1600   \n",
       "1523300157      1076     2.0           0     0          3      7        1020   \n",
       "\n",
       "            sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "id                                                                             \n",
       "7129300520              0      1955             0    98178  47.5112 -122.257   \n",
       "6414100192            400      1951          1991    98125  47.7210 -122.319   \n",
       "5631500400              0      1933             0    98028  47.7379 -122.233   \n",
       "2487200875            910      1965             0    98136  47.5208 -122.393   \n",
       "1954400510              0      1987             0    98074  47.6168 -122.045   \n",
       "...                   ...       ...           ...      ...      ...      ...   \n",
       "263000018               0      2009             0    98103  47.6993 -122.346   \n",
       "6600060120              0      2014             0    98146  47.5107 -122.362   \n",
       "1523300141              0      2009             0    98144  47.5944 -122.299   \n",
       "291310100               0      2004             0    98027  47.5345 -122.069   \n",
       "1523300157              0      2008             0    98144  47.5941 -122.299   \n",
       "\n",
       "            sqft_living15  sqft_lot15  \n",
       "id                                     \n",
       "7129300520           1340        5650  \n",
       "6414100192           1690        7639  \n",
       "5631500400           2720        8062  \n",
       "2487200875           1360        5000  \n",
       "1954400510           1800        7503  \n",
       "...                   ...         ...  \n",
       "263000018            1530        1509  \n",
       "6600060120           1830        7200  \n",
       "1523300141           1020        2007  \n",
       "291310100            1410        1287  \n",
       "1523300157           1020        1357  \n",
       "\n",
       "[21613 rows x 20 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c9fe547-87fd-4dd8-ab3e-39b0f918ff49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_df??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dafbe8f0-d7b4-4cdb-8a5c-8a82d6296c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n",
       "       'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
       "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
       "       'sqft_living15', 'sqft_lot15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebcc0116-3789-4a85-b69a-649228df6afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
       "       'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
       "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
       "       'sqft_living15', 'sqft_lot15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a88274a-1950-4387-80f4-0b6a2dcacca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ppltn_qty', 'urbn_ppltn_qty', 'sbrbn_ppltn_qty', 'farm_ppltn_qty',\n",
       "       'non_farm_qty', 'medn_hshld_incm_amt', 'medn_incm_per_prsn_amt',\n",
       "       'hous_val_amt', 'edctn_less_than_9_qty', 'edctn_9_12_qty',\n",
       "       'edctn_high_schl_qty', 'edctn_some_clg_qty', 'edctn_assoc_dgre_qty',\n",
       "       'edctn_bchlr_dgre_qty', 'edctn_prfsnl_qty', 'per_urbn', 'per_sbrbn',\n",
       "       'per_farm', 'per_non_farm', 'per_less_than_9', 'per_9_to_12', 'per_hsd',\n",
       "       'per_some_clg', 'per_assoc', 'per_bchlr', 'per_prfsnl', 'zipcode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fb9b768-cb11-4447-ac26-75bc4dbd4019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.pkl  model_features.json\n"
     ]
    }
   ],
   "source": [
    "!ls ../model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2f77869-6668-4ca2-8060-bdc239e53d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found features file at: ../model/model_features.json\n",
      "Model features: ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'sqft_above', 'sqft_basement', 'ppltn_qty', 'urbn_ppltn_qty', 'sbrbn_ppltn_qty', 'farm_ppltn_qty', 'non_farm_qty', 'medn_hshld_incm_amt', 'medn_incm_per_prsn_amt', 'hous_val_amt', 'edctn_less_than_9_qty', 'edctn_9_12_qty', 'edctn_high_schl_qty', 'edctn_some_clg_qty', 'edctn_assoc_dgre_qty', 'edctn_bchlr_dgre_qty', 'edctn_prfsnl_qty', 'per_urbn', 'per_sbrbn', 'per_farm', 'per_non_farm', 'per_less_than_9', 'per_9_to_12', 'per_hsd', 'per_some_clg', 'per_assoc', 'per_bchlr', 'per_prfsnl']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Check different possible locations\n",
    "possible_paths = [\n",
    "    Path(\"model_features.json\"),  # current directory\n",
    "    Path(\"model/model_features.json\"),  # model subdirectory\n",
    "    Path(\"../model/model_features.json\"),  # parent directory\n",
    "    Path(\"data/model_features.json\"),  # data directory if you have one\n",
    "]\n",
    "\n",
    "for path in possible_paths:\n",
    "    if path.exists():\n",
    "        print(f\"Found features file at: {path}\")\n",
    "        model_features = json.loads(path.read_text())\n",
    "        print(\"Model features:\", model_features)\n",
    "        break\n",
    "else:\n",
    "    print(\"model_features.json not found in any expected location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9021b31-19cd-4cae-a1b8-83c79c7c5423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.columns),len(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf5b15e7-ff31-4f51-8fac-ff38c9db1eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ppltn_qty</th>\n",
       "      <th>urbn_ppltn_qty</th>\n",
       "      <th>sbrbn_ppltn_qty</th>\n",
       "      <th>farm_ppltn_qty</th>\n",
       "      <th>non_farm_qty</th>\n",
       "      <th>medn_hshld_incm_amt</th>\n",
       "      <th>medn_incm_per_prsn_amt</th>\n",
       "      <th>hous_val_amt</th>\n",
       "      <th>edctn_less_than_9_qty</th>\n",
       "      <th>edctn_9_12_qty</th>\n",
       "      <th>...</th>\n",
       "      <th>per_farm</th>\n",
       "      <th>per_non_farm</th>\n",
       "      <th>per_less_than_9</th>\n",
       "      <th>per_9_to_12</th>\n",
       "      <th>per_hsd</th>\n",
       "      <th>per_some_clg</th>\n",
       "      <th>per_assoc</th>\n",
       "      <th>per_bchlr</th>\n",
       "      <th>per_prfsnl</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38249.0</td>\n",
       "      <td>37394.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>66051.0</td>\n",
       "      <td>25219.0</td>\n",
       "      <td>192000.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>2301.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>98042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22036.0</td>\n",
       "      <td>22036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91904.0</td>\n",
       "      <td>53799.0</td>\n",
       "      <td>573900.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18194.0</td>\n",
       "      <td>18194.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61813.0</td>\n",
       "      <td>31765.0</td>\n",
       "      <td>246600.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>98028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21956.0</td>\n",
       "      <td>21956.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47461.0</td>\n",
       "      <td>22158.0</td>\n",
       "      <td>175400.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>1773.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>98178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22814.0</td>\n",
       "      <td>22814.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48606.0</td>\n",
       "      <td>28398.0</td>\n",
       "      <td>252600.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>98007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>35140.0</td>\n",
       "      <td>35021.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>81929.0</td>\n",
       "      <td>41856.0</td>\n",
       "      <td>335900.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>98006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>23926.5</td>\n",
       "      <td>23298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56933.0</td>\n",
       "      <td>27639.5</td>\n",
       "      <td>239850.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>98074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>23926.5</td>\n",
       "      <td>23298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56933.0</td>\n",
       "      <td>27639.5</td>\n",
       "      <td>239850.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>98077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>23926.5</td>\n",
       "      <td>23298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56933.0</td>\n",
       "      <td>27639.5</td>\n",
       "      <td>239850.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>98030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>23926.5</td>\n",
       "      <td>23298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56933.0</td>\n",
       "      <td>27639.5</td>\n",
       "      <td>239850.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>98075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ppltn_qty  urbn_ppltn_qty  sbrbn_ppltn_qty  farm_ppltn_qty  non_farm_qty  \\\n",
       "0     38249.0         37394.0              0.0             0.0         855.0   \n",
       "1     22036.0         22036.0              0.0             0.0           0.0   \n",
       "2     18194.0         18194.0              0.0             0.0           0.0   \n",
       "3     21956.0         21956.0              0.0             0.0           0.0   \n",
       "4     22814.0         22814.0              0.0             0.0           0.0   \n",
       "..        ...             ...              ...             ...           ...   \n",
       "65    35140.0         35021.0              0.0             0.0         119.0   \n",
       "66    23926.5         23298.0              0.0             0.0           0.0   \n",
       "67    23926.5         23298.0              0.0             0.0           0.0   \n",
       "68    23926.5         23298.0              0.0             0.0           0.0   \n",
       "69    23926.5         23298.0              0.0             0.0           0.0   \n",
       "\n",
       "    medn_hshld_incm_amt  medn_incm_per_prsn_amt  hous_val_amt  \\\n",
       "0               66051.0                 25219.0      192000.0   \n",
       "1               91904.0                 53799.0      573900.0   \n",
       "2               61813.0                 31765.0      246600.0   \n",
       "3               47461.0                 22158.0      175400.0   \n",
       "4               48606.0                 28398.0      252600.0   \n",
       "..                  ...                     ...           ...   \n",
       "65              81929.0                 41856.0      335900.0   \n",
       "66              56933.0                 27639.5      239850.0   \n",
       "67              56933.0                 27639.5      239850.0   \n",
       "68              56933.0                 27639.5      239850.0   \n",
       "69              56933.0                 27639.5      239850.0   \n",
       "\n",
       "    edctn_less_than_9_qty  edctn_9_12_qty  ...  per_farm  per_non_farm  \\\n",
       "0                   437.0          2301.0  ...       0.0           2.0   \n",
       "1                   149.0           404.0  ...       0.0           0.0   \n",
       "2                   269.0           905.0  ...       0.0           0.0   \n",
       "3                   925.0          1773.0  ...       0.0           0.0   \n",
       "4                   599.0          1148.0  ...       0.0           0.0   \n",
       "..                    ...             ...  ...       ...           ...   \n",
       "65                  212.0           865.0  ...       0.0           0.0   \n",
       "66                  406.0          1213.0  ...       0.0           0.0   \n",
       "67                  406.0          1213.0  ...       0.0           0.0   \n",
       "68                  406.0          1213.0  ...       0.0           0.0   \n",
       "69                  406.0          1213.0  ...       0.0           0.0   \n",
       "\n",
       "    per_less_than_9  per_9_to_12  per_hsd  per_some_clg  per_assoc  per_bchlr  \\\n",
       "0               1.0          6.0     18.0          20.0        5.0       12.0   \n",
       "1               0.0          1.0      6.0          12.0        3.0       27.0   \n",
       "2               1.0          4.0     13.0          20.0        6.0       19.0   \n",
       "3               4.0          8.0     20.0          21.0        5.0       12.0   \n",
       "4               2.0          5.0     13.0          17.0        5.0       23.0   \n",
       "..              ...          ...      ...           ...        ...        ...   \n",
       "65              0.0          2.0      8.0          15.0        4.0       27.0   \n",
       "66              1.0          5.0     15.0          19.0        5.0       19.0   \n",
       "67              1.0          5.0     15.0          19.0        5.0       19.0   \n",
       "68              1.0          5.0     15.0          19.0        5.0       19.0   \n",
       "69              1.0          5.0     15.0          19.0        5.0       19.0   \n",
       "\n",
       "    per_prfsnl  zipcode  \n",
       "0          4.0    98042  \n",
       "1         22.0    98040  \n",
       "2          9.0    98028  \n",
       "3          4.0    98178  \n",
       "4         12.0    98007  \n",
       "..         ...      ...  \n",
       "65        15.0    98006  \n",
       "66         7.5    98074  \n",
       "67         7.5    98077  \n",
       "68         7.5    98030  \n",
       "69         7.5    98075  \n",
       "\n",
       "[70 rows x 27 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b1702f2-ac7d-4b77-8499-199a6edbd657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>5043</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "      <td>98118</td>\n",
       "      <td>47.5354</td>\n",
       "      <td>-122.273</td>\n",
       "      <td>1560</td>\n",
       "      <td>5765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2220</td>\n",
       "      <td>6380</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1660</td>\n",
       "      <td>560</td>\n",
       "      <td>1931</td>\n",
       "      <td>0</td>\n",
       "      <td>98115</td>\n",
       "      <td>47.6974</td>\n",
       "      <td>-122.313</td>\n",
       "      <td>950</td>\n",
       "      <td>6380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1630</td>\n",
       "      <td>10962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1100</td>\n",
       "      <td>530</td>\n",
       "      <td>1977</td>\n",
       "      <td>0</td>\n",
       "      <td>98030</td>\n",
       "      <td>47.3801</td>\n",
       "      <td>-122.166</td>\n",
       "      <td>1830</td>\n",
       "      <td>8470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1710</td>\n",
       "      <td>9720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>1974</td>\n",
       "      <td>0</td>\n",
       "      <td>98005</td>\n",
       "      <td>47.5903</td>\n",
       "      <td>-122.157</td>\n",
       "      <td>2270</td>\n",
       "      <td>9672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>850</td>\n",
       "      <td>6370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>1951</td>\n",
       "      <td>0</td>\n",
       "      <td>98126</td>\n",
       "      <td>47.5198</td>\n",
       "      <td>-122.373</td>\n",
       "      <td>850</td>\n",
       "      <td>5170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2430</td>\n",
       "      <td>54059</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2430</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.4664</td>\n",
       "      <td>-121.992</td>\n",
       "      <td>2910</td>\n",
       "      <td>49658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1240</td>\n",
       "      <td>1249</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1240</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>98107</td>\n",
       "      <td>47.6718</td>\n",
       "      <td>-122.386</td>\n",
       "      <td>1240</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1860</td>\n",
       "      <td>9750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1460</td>\n",
       "      <td>400</td>\n",
       "      <td>1969</td>\n",
       "      <td>0</td>\n",
       "      <td>98034</td>\n",
       "      <td>47.7097</td>\n",
       "      <td>-122.202</td>\n",
       "      <td>1900</td>\n",
       "      <td>8913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2330</td>\n",
       "      <td>3800</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1360</td>\n",
       "      <td>970</td>\n",
       "      <td>1927</td>\n",
       "      <td>0</td>\n",
       "      <td>98115</td>\n",
       "      <td>47.6835</td>\n",
       "      <td>-122.308</td>\n",
       "      <td>2100</td>\n",
       "      <td>3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2550</td>\n",
       "      <td>4630</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2550</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>98075</td>\n",
       "      <td>47.5928</td>\n",
       "      <td>-122.004</td>\n",
       "      <td>2550</td>\n",
       "      <td>5151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \\\n",
       "0          4       1.00         1680      5043     1.5           0     0   \n",
       "1          3       2.50         2220      6380     1.5           0     0   \n",
       "2          3       2.25         1630     10962     1.0           0     0   \n",
       "3          5       2.50         1710      9720     2.0           0     0   \n",
       "4          2       1.00          850      6370     1.0           0     0   \n",
       "..       ...        ...          ...       ...     ...         ...   ...   \n",
       "95         3       2.50         2430     54059     2.0           0     0   \n",
       "96         2       2.50         1240      1249     3.0           0     0   \n",
       "97         4       1.75         1860      9750     1.0           0     0   \n",
       "98         5       1.75         2330      3800     1.5           0     0   \n",
       "99         4       2.50         2550      4630     2.0           0     0   \n",
       "\n",
       "    condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
       "0           4      6        1680              0      1911             0   \n",
       "1           4      8        1660            560      1931             0   \n",
       "2           4      8        1100            530      1977             0   \n",
       "3           4      8        1710              0      1974             0   \n",
       "4           3      6         850              0      1951             0   \n",
       "..        ...    ...         ...            ...       ...           ...   \n",
       "95          3     10        2430              0      1987             0   \n",
       "96          3      8        1240              0      2006             0   \n",
       "97          3      7        1460            400      1969             0   \n",
       "98          3      7        1360            970      1927             0   \n",
       "99          3      7        2550              0      2005             0   \n",
       "\n",
       "    zipcode      lat     long  sqft_living15  sqft_lot15  \n",
       "0     98118  47.5354 -122.273           1560        5765  \n",
       "1     98115  47.6974 -122.313            950        6380  \n",
       "2     98030  47.3801 -122.166           1830        8470  \n",
       "3     98005  47.5903 -122.157           2270        9672  \n",
       "4     98126  47.5198 -122.373            850        5170  \n",
       "..      ...      ...      ...            ...         ...  \n",
       "95    98027  47.4664 -121.992           2910       49658  \n",
       "96    98107  47.6718 -122.386           1240        2500  \n",
       "97    98034  47.7097 -122.202           1900        8913  \n",
       "98    98115  47.6835 -122.308           2100        3800  \n",
       "99    98075  47.5928 -122.004           2550        5151  \n",
       "\n",
       "[100 rows x 18 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8001cb1-f748-499f-9a0b-0c34a353802d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.pkl  model_features.json\n"
     ]
    }
   ],
   "source": [
    "!ls model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbc508dd-18a6-405a-b679-0134d86d6ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = path/'model/model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fae6e96-2906-41da-98b6-2a3c0b6b29ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path=\"../model/model.pkl\"):\n",
    "    \"\"\"\n",
    "    Function to load the model\n",
    "\n",
    "    Args\n",
    "    model_path: the path to the model\n",
    "    \"\"\"\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Loading existing model from pickle at {model_path}\")\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        return model\n",
    "    else:\n",
    "        print(f\"Model file not found at {model_path}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31e95552-bce1-4c67-a5f6-e53c57944460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.load_model(model_path='model/model.pkl')>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75d87673-a897-4713-862f-20a916827ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m load_model(model_path=\u001b[33m'model/model.pkl'\u001b[39m)\n",
       "\u001b[31mSource:\u001b[39m   \n",
       "\u001b[38;5;28;01mdef\u001b[39;00m load_model(model_path=\u001b[33m\"model/model.pkl\"\u001b[39m):\n",
       "    \u001b[33m\"\"\"\u001b[39m\n",
       "\u001b[33m    Function to load the model\u001b[39m\n",
       "\n",
       "\u001b[33m    Args\u001b[39m\n",
       "\u001b[33m    model_path: the path to the model\u001b[39m\n",
       "\u001b[33m    \"\"\"\u001b[39m\n",
       "    \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(model_path):\n",
       "        print(f\"Loading existing model from pickle at {model_path}\")\n",
       "        \u001b[38;5;28;01mwith\u001b[39;00m open(model_path, \u001b[33m'rb'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
       "            model = pickle.load(f)\n",
       "        \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
       "    \u001b[38;5;28;01melse\u001b[39;00m:\n",
       "        print(f\"Model file not found at {model_path}\")\n",
       "        \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
       "\u001b[31mFile:\u001b[39m      /tmp/ipykernel_100471/1537687095.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_model??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd22493-bf97-4cc3-89fa-9383bb813824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model from pickle at ../model/model.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;robustscaler&#x27;, RobustScaler()),\n",
       "                (&#x27;kneighborsregressor&#x27;, KNeighborsRegressor())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">steps&nbsp;</td>\n",
       "            <td class=\"value\">[(&#x27;robustscaler&#x27;, ...), (&#x27;kneighborsregressor&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">transform_input&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">memory&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RobustScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.preprocessing.RobustScaler.html\">?<span>Documentation for RobustScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"robustscaler__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_centering',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">with_centering&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">with_scaling&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('quantile_range',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">quantile_range&nbsp;</td>\n",
       "            <td class=\"value\">(25.0, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('unit_variance',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">unit_variance&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KNeighborsRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\">?<span>Documentation for KNeighborsRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"kneighborsregressor__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_neighbors',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_neighbors&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">weights&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;uniform&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('algorithm',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">algorithm&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('leaf_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">leaf_size&nbsp;</td>\n",
       "            <td class=\"value\">30</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('p',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">p&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">metric&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;minkowski&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('metric_params',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">metric_params&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('robustscaler', RobustScaler()),\n",
       "                ('kneighborsregressor', KNeighborsRegressor())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61b3d6bc-c336-4457-b1ed-e8bb20321803",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- condition\n- grade\n- lat\n- long\n- sqft_living15\n- ...\nFeature names seen at fit time, yet now missing:\n- edctn_9_12_qty\n- edctn_assoc_dgre_qty\n- edctn_bchlr_dgre_qty\n- edctn_high_schl_qty\n- edctn_less_than_9_qty\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/sklearn/pipeline.py:788\u001b[39m, in \u001b[36mPipeline.predict\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[32m    787\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m         Xt = \u001b[43mtransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m].predict(Xt, **params)\n\u001b[32m    791\u001b[39m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:1700\u001b[39m, in \u001b[36mRobustScaler.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1687\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Center and scale the data.\u001b[39;00m\n\u001b[32m   1688\u001b[39m \n\u001b[32m   1689\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1697\u001b[39m \u001b[33;03m    Transformed array.\u001b[39;00m\n\u001b[32m   1698\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1699\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1700\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1701\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1702\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1703\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1704\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1705\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1707\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1709\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1711\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sparse.issparse(X):\n\u001b[32m   1712\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.with_scaling:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/sklearn/utils/validation.py:2929\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2845\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_data\u001b[39m(\n\u001b[32m   2846\u001b[39m     _estimator,\n\u001b[32m   2847\u001b[39m     /,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2853\u001b[39m     **check_params,\n\u001b[32m   2854\u001b[39m ):\n\u001b[32m   2855\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[32m   2856\u001b[39m \n\u001b[32m   2857\u001b[39m \u001b[33;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2927\u001b[39m \u001b[33;03m        validated.\u001b[39;00m\n\u001b[32m   2928\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2929\u001b[39m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2930\u001b[39m     tags = get_tags(_estimator)\n\u001b[32m   2931\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags.target_tags.required:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/sklearn/utils/validation.py:2787\u001b[39m, in \u001b[36m_check_feature_names\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[32m   2785\u001b[39m     message += \u001b[33m\"\u001b[39m\u001b[33mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2787\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[31mValueError\u001b[39m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- condition\n- grade\n- lat\n- long\n- sqft_living15\n- ...\nFeature names seen at fit time, yet now missing:\n- edctn_9_12_qty\n- edctn_assoc_dgre_qty\n- edctn_bchlr_dgre_qty\n- edctn_high_schl_qty\n- edctn_less_than_9_qty\n- ...\n"
     ]
    }
   ],
   "source": [
    "#model.predict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5755f233-34dd-4702-8c6e-b645607924c1",
   "metadata": {},
   "source": [
    "## Trial solution 1 - chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b71b5b2d-754d-49e0-8f00-6f7ad851893e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>...</th>\n",
       "      <th>per_sbrbn</th>\n",
       "      <th>per_farm</th>\n",
       "      <th>per_non_farm</th>\n",
       "      <th>per_less_than_9</th>\n",
       "      <th>per_9_to_12</th>\n",
       "      <th>per_hsd</th>\n",
       "      <th>per_some_clg</th>\n",
       "      <th>per_assoc</th>\n",
       "      <th>per_bchlr</th>\n",
       "      <th>per_prfsnl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>5043</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2220</td>\n",
       "      <td>6380</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1630</td>\n",
       "      <td>10962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1710</td>\n",
       "      <td>9720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>850</td>\n",
       "      <td>6370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2430</td>\n",
       "      <td>54059</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1240</td>\n",
       "      <td>1249</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1860</td>\n",
       "      <td>9750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2330</td>\n",
       "      <td>3800</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2550</td>\n",
       "      <td>4630</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \\\n",
       "0          4       1.00         1680      5043     1.5           0     0   \n",
       "1          3       2.50         2220      6380     1.5           0     0   \n",
       "2          3       2.25         1630     10962     1.0           0     0   \n",
       "3          5       2.50         1710      9720     2.0           0     0   \n",
       "4          2       1.00          850      6370     1.0           0     0   \n",
       "..       ...        ...          ...       ...     ...         ...   ...   \n",
       "95         3       2.50         2430     54059     2.0           0     0   \n",
       "96         2       2.50         1240      1249     3.0           0     0   \n",
       "97         4       1.75         1860      9750     1.0           0     0   \n",
       "98         5       1.75         2330      3800     1.5           0     0   \n",
       "99         4       2.50         2550      4630     2.0           0     0   \n",
       "\n",
       "    condition  grade  sqft_above  ...  per_sbrbn  per_farm  per_non_farm  \\\n",
       "0           4      6        1680  ...        0.0       0.0           0.0   \n",
       "1           4      8        1660  ...        0.0       0.0           0.0   \n",
       "2           4      8        1100  ...        0.0       0.0           0.0   \n",
       "3           4      8        1710  ...        0.0       0.0           0.0   \n",
       "4           3      6         850  ...        0.0       0.0           0.0   \n",
       "..        ...    ...         ...  ...        ...       ...           ...   \n",
       "95          3     10        2430  ...        0.0       0.0          19.0   \n",
       "96          3      8        1240  ...        0.0       0.0           0.0   \n",
       "97          3      7        1460  ...        0.0       0.0           0.0   \n",
       "98          3      7        1360  ...        0.0       0.0           0.0   \n",
       "99          3      7        2550  ...        0.0       0.0           0.0   \n",
       "\n",
       "   per_less_than_9  per_9_to_12  per_hsd  per_some_clg  per_assoc  per_bchlr  \\\n",
       "0              9.0          9.0     17.0          15.0        4.0       11.0   \n",
       "1              0.0          2.0      8.0          15.0        4.0       30.0   \n",
       "2              1.0          5.0     15.0          19.0        5.0       19.0   \n",
       "3              2.0          3.0     10.0          17.0        4.0       26.0   \n",
       "4              4.0          7.0     16.0          19.0        5.0       16.0   \n",
       "..             ...          ...      ...           ...        ...        ...   \n",
       "95             1.0          3.0     12.0          17.0        6.0       24.0   \n",
       "96             1.0          5.0     14.0          20.0        5.0       28.0   \n",
       "97             1.0          4.0     14.0          21.0        6.0       20.0   \n",
       "98             0.0          2.0      8.0          15.0        4.0       30.0   \n",
       "99             1.0          5.0     15.0          19.0        5.0       19.0   \n",
       "\n",
       "    per_prfsnl  \n",
       "0          6.0  \n",
       "1         20.0  \n",
       "2          7.5  \n",
       "3         16.0  \n",
       "4          7.0  \n",
       "..         ...  \n",
       "95        11.0  \n",
       "96        11.0  \n",
       "97         8.0  \n",
       "98        20.0  \n",
       "99         7.5  \n",
       "\n",
       "[100 rows x 44 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --------------------------\n",
    "# Example: model_expected list\n",
    "# --------------------------\n",
    "model_expected = [\n",
    "    'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
    "    'sqft_above', 'sqft_basement',\n",
    "    'ppltn_qty', 'urbn_ppltn_qty', 'sbrbn_ppltn_qty', 'farm_ppltn_qty', 'non_farm_qty',\n",
    "    'medn_hshld_incm_amt', 'medn_incm_per_prsn_amt', 'hous_val_amt',\n",
    "    'edctn_less_than_9_qty', 'edctn_9_12_qty', 'edctn_high_schl_qty', 'edctn_some_clg_qty',\n",
    "    'edctn_assoc_dgre_qty', 'edctn_bchlr_dgre_qty', 'edctn_prfsnl_qty',\n",
    "    'per_urbn', 'per_sbrbn', 'per_farm', 'per_non_farm',\n",
    "    'per_less_than_9', 'per_9_to_12', 'per_hsd', 'per_some_clg',\n",
    "    'per_assoc', 'per_bchlr', 'per_prfsnl'\n",
    "]\n",
    "\n",
    "# --------------------------\n",
    "# 1. Merge housing with demographics\n",
    "# --------------------------\n",
    "# Ensure zipcodes are the same dtype (string recommended to preserve leading zeros)\n",
    "test_df['zipcode'] = test_df['zipcode'].astype(str)\n",
    "demographics_df['zipcode'] = demographics_df['zipcode'].astype(str)\n",
    "\n",
    "# Merge on zipcode\n",
    "inference_df = test_df.merge(demographics_df, on='zipcode', how='left')\n",
    "inference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "056d8a33-2ce4-43ab-aa04-3b0cfcf91ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 18), (70, 27), (100, 44))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape,demographics_df.shape,inference_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa7636d5-30b8-4bd0-b8a9-b7f999a318b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
       "       'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
       "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
       "       'sqft_living15', 'sqft_lot15', 'ppltn_qty', 'urbn_ppltn_qty',\n",
       "       'sbrbn_ppltn_qty', 'farm_ppltn_qty', 'non_farm_qty',\n",
       "       'medn_hshld_incm_amt', 'medn_incm_per_prsn_amt', 'hous_val_amt',\n",
       "       'edctn_less_than_9_qty', 'edctn_9_12_qty', 'edctn_high_schl_qty',\n",
       "       'edctn_some_clg_qty', 'edctn_assoc_dgre_qty', 'edctn_bchlr_dgre_qty',\n",
       "       'edctn_prfsnl_qty', 'per_urbn', 'per_sbrbn', 'per_farm', 'per_non_farm',\n",
       "       'per_less_than_9', 'per_9_to_12', 'per_hsd', 'per_some_clg',\n",
       "       'per_assoc', 'per_bchlr', 'per_prfsnl'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4587d2c5-d8ee-484e-bf90-59931ca972bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All expected features are present after merge.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------\n",
    "# 2. Check coverage of expected features\n",
    "# --------------------------\n",
    "missing_features = set(model_expected) - set(inference_df.columns)\n",
    "if missing_features:\n",
    "    print(\"WARNING: These expected features are missing after merge:\", missing_features)\n",
    "else:\n",
    "    print(\"All expected features are present after merge.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58dfdc25-e3d7-446a-a6eb-1f23db991f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   bedrooms       100 non-null    int64  \n",
      " 1   bathrooms      100 non-null    float64\n",
      " 2   sqft_living    100 non-null    int64  \n",
      " 3   sqft_lot       100 non-null    int64  \n",
      " 4   floors         100 non-null    float64\n",
      " 5   waterfront     100 non-null    int64  \n",
      " 6   view           100 non-null    int64  \n",
      " 7   condition      100 non-null    int64  \n",
      " 8   grade          100 non-null    int64  \n",
      " 9   sqft_above     100 non-null    int64  \n",
      " 10  sqft_basement  100 non-null    int64  \n",
      " 11  yr_built       100 non-null    int64  \n",
      " 12  yr_renovated   100 non-null    int64  \n",
      " 13  zipcode        100 non-null    object \n",
      " 14  lat            100 non-null    float64\n",
      " 15  long           100 non-null    float64\n",
      " 16  sqft_living15  100 non-null    int64  \n",
      " 17  sqft_lot15     100 non-null    int64  \n",
      "dtypes: float64(4), int64(13), object(1)\n",
      "memory usage: 14.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df9ac837-9326-44e0-a58e-8c43ca707b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bedrooms         0\n",
       "bathrooms        0\n",
       "sqft_living      0\n",
       "sqft_lot         0\n",
       "floors           0\n",
       "waterfront       0\n",
       "view             0\n",
       "condition        0\n",
       "grade            0\n",
       "sqft_above       0\n",
       "sqft_basement    0\n",
       "yr_built         0\n",
       "yr_renovated     0\n",
       "zipcode          0\n",
       "lat              0\n",
       "long             0\n",
       "sqft_living15    0\n",
       "sqft_lot15       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc09970e-2a93-403f-b768-5e9576e61c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------\n",
    "# 3. Impute missing values (basic strategy: median imputation)\n",
    "# --------------------------\n",
    "# (In production you should use the exact imputation strategy/scaler from training.)\n",
    "for col in model_expected:\n",
    "    if inference_df[col].isnull().any():\n",
    "        median_val = inference_df[col].median()\n",
    "        inference_df[col] = inference_df[col].fillna(median_val)\n",
    "        print(f\"Filled NaNs in {col} with median {median_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "896fa84b-24e6-44c7-95d4-b88d58546887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>ppltn_qty</th>\n",
       "      <th>urbn_ppltn_qty</th>\n",
       "      <th>sbrbn_ppltn_qty</th>\n",
       "      <th>...</th>\n",
       "      <th>per_sbrbn</th>\n",
       "      <th>per_farm</th>\n",
       "      <th>per_non_farm</th>\n",
       "      <th>per_less_than_9</th>\n",
       "      <th>per_9_to_12</th>\n",
       "      <th>per_hsd</th>\n",
       "      <th>per_some_clg</th>\n",
       "      <th>per_assoc</th>\n",
       "      <th>per_bchlr</th>\n",
       "      <th>per_prfsnl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>5043</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>40409.0</td>\n",
       "      <td>40409.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2220</td>\n",
       "      <td>6380</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1660</td>\n",
       "      <td>560</td>\n",
       "      <td>43263.0</td>\n",
       "      <td>43263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1630</td>\n",
       "      <td>10962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1100</td>\n",
       "      <td>530</td>\n",
       "      <td>23926.5</td>\n",
       "      <td>23298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1710</td>\n",
       "      <td>9720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>17150.0</td>\n",
       "      <td>17150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>850</td>\n",
       "      <td>6370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>19435.0</td>\n",
       "      <td>19435.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2430</td>\n",
       "      <td>54059</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2430</td>\n",
       "      <td>0</td>\n",
       "      <td>22271.0</td>\n",
       "      <td>18009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1240</td>\n",
       "      <td>1249</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>0</td>\n",
       "      <td>18314.0</td>\n",
       "      <td>18314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1860</td>\n",
       "      <td>9750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1460</td>\n",
       "      <td>400</td>\n",
       "      <td>40127.0</td>\n",
       "      <td>40127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2330</td>\n",
       "      <td>3800</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1360</td>\n",
       "      <td>970</td>\n",
       "      <td>43263.0</td>\n",
       "      <td>43263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2550</td>\n",
       "      <td>4630</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2550</td>\n",
       "      <td>0</td>\n",
       "      <td>23926.5</td>\n",
       "      <td>23298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bedrooms  bathrooms  sqft_living  sqft_lot  floors  sqft_above  \\\n",
       "0          4       1.00         1680      5043     1.5        1680   \n",
       "1          3       2.50         2220      6380     1.5        1660   \n",
       "2          3       2.25         1630     10962     1.0        1100   \n",
       "3          5       2.50         1710      9720     2.0        1710   \n",
       "4          2       1.00          850      6370     1.0         850   \n",
       "..       ...        ...          ...       ...     ...         ...   \n",
       "95         3       2.50         2430     54059     2.0        2430   \n",
       "96         2       2.50         1240      1249     3.0        1240   \n",
       "97         4       1.75         1860      9750     1.0        1460   \n",
       "98         5       1.75         2330      3800     1.5        1360   \n",
       "99         4       2.50         2550      4630     2.0        2550   \n",
       "\n",
       "    sqft_basement  ppltn_qty  urbn_ppltn_qty  sbrbn_ppltn_qty  ...  per_sbrbn  \\\n",
       "0               0    40409.0         40409.0              0.0  ...        0.0   \n",
       "1             560    43263.0         43263.0              0.0  ...        0.0   \n",
       "2             530    23926.5         23298.0              0.0  ...        0.0   \n",
       "3               0    17150.0         17150.0              0.0  ...        0.0   \n",
       "4               0    19435.0         19435.0              0.0  ...        0.0   \n",
       "..            ...        ...             ...              ...  ...        ...   \n",
       "95              0    22271.0         18009.0              0.0  ...        0.0   \n",
       "96              0    18314.0         18314.0              0.0  ...        0.0   \n",
       "97            400    40127.0         40127.0              0.0  ...        0.0   \n",
       "98            970    43263.0         43263.0              0.0  ...        0.0   \n",
       "99              0    23926.5         23298.0              0.0  ...        0.0   \n",
       "\n",
       "    per_farm  per_non_farm  per_less_than_9  per_9_to_12  per_hsd  \\\n",
       "0        0.0           0.0              9.0          9.0     17.0   \n",
       "1        0.0           0.0              0.0          2.0      8.0   \n",
       "2        0.0           0.0              1.0          5.0     15.0   \n",
       "3        0.0           0.0              2.0          3.0     10.0   \n",
       "4        0.0           0.0              4.0          7.0     16.0   \n",
       "..       ...           ...              ...          ...      ...   \n",
       "95       0.0          19.0              1.0          3.0     12.0   \n",
       "96       0.0           0.0              1.0          5.0     14.0   \n",
       "97       0.0           0.0              1.0          4.0     14.0   \n",
       "98       0.0           0.0              0.0          2.0      8.0   \n",
       "99       0.0           0.0              1.0          5.0     15.0   \n",
       "\n",
       "    per_some_clg  per_assoc  per_bchlr  per_prfsnl  \n",
       "0           15.0        4.0       11.0         6.0  \n",
       "1           15.0        4.0       30.0        20.0  \n",
       "2           19.0        5.0       19.0         7.5  \n",
       "3           17.0        4.0       26.0        16.0  \n",
       "4           19.0        5.0       16.0         7.0  \n",
       "..           ...        ...        ...         ...  \n",
       "95          17.0        6.0       24.0        11.0  \n",
       "96          20.0        5.0       28.0        11.0  \n",
       "97          21.0        6.0       20.0         8.0  \n",
       "98          15.0        4.0       30.0        20.0  \n",
       "99          19.0        5.0       19.0         7.5  \n",
       "\n",
       "[100 rows x 33 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --------------------------\n",
    "# 4. Reorder columns to match model input order\n",
    "# --------------------------\n",
    "inference_df = inference_df[model_expected]\n",
    "inference_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2522b9e-1c4c-43ee-976e-48cc5678271d",
   "metadata": {},
   "source": [
    "### How reodering works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a24b4b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>floors</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>98118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>98115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>98107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>98115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bedrooms  floors zipcode\n",
       "0          4     1.5   98118\n",
       "1          3     1.5   98115\n",
       "2          3     1.0   98030\n",
       "3          5     2.0   98005\n",
       "4          2     1.0   98126\n",
       "..       ...     ...     ...\n",
       "95         3     2.0   98027\n",
       "96         2     3.0   98107\n",
       "97         4     1.0   98034\n",
       "98         5     1.5   98115\n",
       "99         4     2.0   98075\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 4. Reorder columns to match model input order\n",
    "# --------------------------\n",
    "inference_df_d = test_df.merge(demographics_df, on='zipcode', how='left').copy()\n",
    "inference_df_a = inference_df_d.copy()\n",
    "inference_df_b = inference_df_a[['bedrooms','floors','zipcode']]\n",
    "inference_df_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07f536cf-8846-4927-99aa-9038d46df64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (100, 33)\n",
      "Any NaNs left? False\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 5. Type consistency: ensure all numeric\n",
    "# --------------------------\n",
    "#inference_df = inference_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# --------------------------\n",
    "# 6. Final sanity checks\n",
    "# --------------------------\n",
    "print(\"Final shape:\", inference_df.shape)\n",
    "print(\"Any NaNs left?\", inference_df.isna().any().any())\n",
    "\n",
    "# Now you can feed inference_df into your trained model:\n",
    "# preds = model.predict(inference_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef3a3f44-bf5e-4fbe-a036-654a88ebed1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51e209ec-bc72-4441-9075-e30d380a9715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(inference_df)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6de6255c-1c54-478a-ac84-5dc8fc5bc6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 458520. ,  612800. ,  449160. ,  679700. ,  304256. ,  553798. ,  341800. ,  445350. ,  990500. ,  532940. ,  422700. ,\n",
       "        484220. ,  499400. ,  358470. ,  790700. ,  236300. ,  426950. ,  687600. ,  619880. ,  438000. ,  520800. ,  669300.2,\n",
       "        549036. ,  411100. ,  250190. ,  313590. ,  730800. ,  285730. ,  256990. ,  390200. ,  285942.4,  865700. ,  975500. ,\n",
       "        494936. ,  272090. ,  297900. ,  302298. ,  612000. ,  222590. ,  297940. ,  213800. ,  796988. ,  407260. ,  307300. ,\n",
       "        451000. ,  263660. ,  297560. ,  658200. ,  261500. ,  288890. , 1241796. ,  279380. ,  252390. ,  252980. ,  569370. ,\n",
       "        524790. ,  602670. ,  427900. ,  406000. ,  890000. ,  486090. ,  317402. ,  886700. ,  421650. ,  321999. ,  390360. ,\n",
       "        486980. ,  499000. ,  344200. ,  558650. ,  264590. ,  711190. ,  259930. ,  614000. ,  424089.8,  522800. ,  520300. ,\n",
       "        412600. ,  830000. ,  258906. ,  726500. ,  565600. ,  220941.6,  404500. ,  412002.8,  795932. ,  184300. ,  562750. ,\n",
       "        540614. ,  364400. ,  242000. ,  644200. ,  272200. ,  500990. ,  831690. ,  535800. ,  452800. ,  471817. ,  609388. ,\n",
       "        573300. ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32a157ed-f1cc-4abb-ae27-6d41b0d94f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 33)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df_c = inference_df.copy()\n",
    "inference_df_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec7e162d-3cdc-4879-841d-801400881269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions written to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(inference_df_c)\n",
    "inference_df_c[\"predicted_price\"] = preds\n",
    "inference_df_c.to_csv(\"predictions.csv\", index=False)\n",
    "print(\"Predictions written to predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf4fd496-0f85-446a-8416-fa2928b2f30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions.csv  sound_realty.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8e932dd-e643-40ff-8435-a9f51ce34e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>ppltn_qty</th>\n",
       "      <th>urbn_ppltn_qty</th>\n",
       "      <th>sbrbn_ppltn_qty</th>\n",
       "      <th>...</th>\n",
       "      <th>per_farm</th>\n",
       "      <th>per_non_farm</th>\n",
       "      <th>per_less_than_9</th>\n",
       "      <th>per_9_to_12</th>\n",
       "      <th>per_hsd</th>\n",
       "      <th>per_some_clg</th>\n",
       "      <th>per_assoc</th>\n",
       "      <th>per_bchlr</th>\n",
       "      <th>per_prfsnl</th>\n",
       "      <th>predicted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>5043</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>40409.0</td>\n",
       "      <td>40409.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>458520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2220</td>\n",
       "      <td>6380</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1660</td>\n",
       "      <td>560</td>\n",
       "      <td>43263.0</td>\n",
       "      <td>43263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>612800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1630</td>\n",
       "      <td>10962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1100</td>\n",
       "      <td>530</td>\n",
       "      <td>23926.5</td>\n",
       "      <td>23298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>449160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1710</td>\n",
       "      <td>9720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>17150.0</td>\n",
       "      <td>17150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>679700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>850</td>\n",
       "      <td>6370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>19435.0</td>\n",
       "      <td>19435.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>304256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2430</td>\n",
       "      <td>54059</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2430</td>\n",
       "      <td>0</td>\n",
       "      <td>22271.0</td>\n",
       "      <td>18009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>535800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1240</td>\n",
       "      <td>1249</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>0</td>\n",
       "      <td>18314.0</td>\n",
       "      <td>18314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>452800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1860</td>\n",
       "      <td>9750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1460</td>\n",
       "      <td>400</td>\n",
       "      <td>40127.0</td>\n",
       "      <td>40127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>471817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2330</td>\n",
       "      <td>3800</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1360</td>\n",
       "      <td>970</td>\n",
       "      <td>43263.0</td>\n",
       "      <td>43263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>609388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2550</td>\n",
       "      <td>4630</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2550</td>\n",
       "      <td>0</td>\n",
       "      <td>23926.5</td>\n",
       "      <td>23298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>573300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bedrooms  bathrooms  sqft_living  sqft_lot  floors  sqft_above  \\\n",
       "0          4       1.00         1680      5043     1.5        1680   \n",
       "1          3       2.50         2220      6380     1.5        1660   \n",
       "2          3       2.25         1630     10962     1.0        1100   \n",
       "3          5       2.50         1710      9720     2.0        1710   \n",
       "4          2       1.00          850      6370     1.0         850   \n",
       "..       ...        ...          ...       ...     ...         ...   \n",
       "95         3       2.50         2430     54059     2.0        2430   \n",
       "96         2       2.50         1240      1249     3.0        1240   \n",
       "97         4       1.75         1860      9750     1.0        1460   \n",
       "98         5       1.75         2330      3800     1.5        1360   \n",
       "99         4       2.50         2550      4630     2.0        2550   \n",
       "\n",
       "    sqft_basement  ppltn_qty  urbn_ppltn_qty  sbrbn_ppltn_qty  ...  per_farm  \\\n",
       "0               0    40409.0         40409.0              0.0  ...       0.0   \n",
       "1             560    43263.0         43263.0              0.0  ...       0.0   \n",
       "2             530    23926.5         23298.0              0.0  ...       0.0   \n",
       "3               0    17150.0         17150.0              0.0  ...       0.0   \n",
       "4               0    19435.0         19435.0              0.0  ...       0.0   \n",
       "..            ...        ...             ...              ...  ...       ...   \n",
       "95              0    22271.0         18009.0              0.0  ...       0.0   \n",
       "96              0    18314.0         18314.0              0.0  ...       0.0   \n",
       "97            400    40127.0         40127.0              0.0  ...       0.0   \n",
       "98            970    43263.0         43263.0              0.0  ...       0.0   \n",
       "99              0    23926.5         23298.0              0.0  ...       0.0   \n",
       "\n",
       "    per_non_farm  per_less_than_9  per_9_to_12  per_hsd  per_some_clg  \\\n",
       "0            0.0              9.0          9.0     17.0          15.0   \n",
       "1            0.0              0.0          2.0      8.0          15.0   \n",
       "2            0.0              1.0          5.0     15.0          19.0   \n",
       "3            0.0              2.0          3.0     10.0          17.0   \n",
       "4            0.0              4.0          7.0     16.0          19.0   \n",
       "..           ...              ...          ...      ...           ...   \n",
       "95          19.0              1.0          3.0     12.0          17.0   \n",
       "96           0.0              1.0          5.0     14.0          20.0   \n",
       "97           0.0              1.0          4.0     14.0          21.0   \n",
       "98           0.0              0.0          2.0      8.0          15.0   \n",
       "99           0.0              1.0          5.0     15.0          19.0   \n",
       "\n",
       "    per_assoc  per_bchlr  per_prfsnl  predicted_price  \n",
       "0         4.0       11.0         6.0         458520.0  \n",
       "1         4.0       30.0        20.0         612800.0  \n",
       "2         5.0       19.0         7.5         449160.0  \n",
       "3         4.0       26.0        16.0         679700.0  \n",
       "4         5.0       16.0         7.0         304256.0  \n",
       "..        ...        ...         ...              ...  \n",
       "95        6.0       24.0        11.0         535800.0  \n",
       "96        5.0       28.0        11.0         452800.0  \n",
       "97        6.0       20.0         8.0         471817.0  \n",
       "98        4.0       30.0        20.0         609388.0  \n",
       "99        5.0       19.0         7.5         573300.0  \n",
       "\n",
       "[100 rows x 34 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.read_csv('predictions.csv')\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8b2cf3f-1fa5-401c-8cbd-b4a108350272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "future_unseen_examples.csv  kc_house_data.csv  zipcode_demographics.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd40609f-976a-419d-986e-901197240aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e27479-3c69-4c09-8eaf-7e03144c4cd6",
   "metadata": {},
   "source": [
    "## API \n",
    "\n",
    "We are now going to start by uploading our data to modal using volumes. To quote the modal documentation\n",
    "\n",
    "Modal Volumes provide a high-performance distributed file system for your modal applications. They are designed for write-once, read-many I/O workloads, like creating machine learning model weights and distributing them for inference.\n",
    "\n",
    "Uploading our data will enable our training function that we run later to access the data it will need to train our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5e9d76a-9ffe-45e3-99c1-3fd18607509d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[31mWas not able to launch web browser\u001b[0me web browserer\n",
      "Please go to this URL manually and complete the flow:\n",
      "\n",
      "\u001b[2K\u001b]8;id=273796;https://modal.com/token-flow/tf-VaMaCbvM7QGYy1Bn0EtX9U\u001b\\\u001b[4;94mhttps://modal.com/token-flow/tf-VaMaCbvM7QGYy1Bn0EtX9U\u001b[0m\u001b]8;;\u001b\\\n",
      "\n",
      "\u001b[2K\u001b[32m⠦\u001b[0m Waiting for authentication in the web browser\n",
      "\u001b[2K\u001b[32m⠹\u001b[0m Waiting for token flow to complete...omplete...\n",
      "\u001b[1A\u001b[2K\u001b[32mWeb authentication finished successfully!\u001b[0m\n",
      "\u001b[32mToken is connected to the \u001b[0m\u001b[35mflexible-functions-ai\u001b[0m\u001b[32m workspace.\u001b[0m\n",
      "Verifying token against \u001b[4;34mhttps://api.modal.com\u001b[0m\n",
      "\u001b[32mToken verified successfully!\u001b[0m\n",
      "\u001b[?25l\u001b[32m⠋\u001b[0m Storing token\n",
      "\u001b[1A\u001b[2K\u001b[32mToken written to \u001b[0m\u001b[35m/home/zicofeadmin/\u001b[0m\u001b[35m.modal.toml\u001b[0m\u001b[32m in profile \u001b[0m\u001b[35mflexible-functions-ai\u001b[0m\u001b[32m.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!modal setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef40c4-b6f4-4905-ad86-b7fbd7c668fd",
   "metadata": {},
   "source": [
    "## Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f137ea1-c9b6-4c8f-b14c-37b717bb88e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "future_unseen_examples.csv  kc_house_data.csv  zipcode_demographics.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbbeefcd-837e-4abe-87e2-dd3185ff3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../data_upload.py ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f2d779-e3b6-4a15-b2f8-2464d040c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "python data_upload.py ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf67c694-5037-434d-af5c-9504af79aa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_286169/1567640505.py:10: DeprecationError: 2025-01-08: modal.Mount usage will soon be deprecated.\n",
      "\n",
      "Use image.add_local_dir instead, which is functionally and performance-wise equivalent.\n",
      "\n",
      "See https://modal.com/docs/guide/modal-1-0-migration for more details.\n",
      "\n",
      "  local_mount = Mount.from_local_dir(\"../data\", remote_path=\"/source_data\")\n"
     ]
    }
   ],
   "source": [
    "from modal import App, Volume, Mount\n",
    "from pathlib import Path\n",
    "import shutil, os\n",
    "\n",
    "app = App(\"sr-data-upload\")\n",
    "\n",
    "volume = Volume.from_name(\"sr-data-volume\", create_if_missing=True)\n",
    "\n",
    "# Mount local ../data into the container at /source_data\n",
    "local_mount = Mount.from_local_dir(\"../data\", remote_path=\"/source_data\")\n",
    "\n",
    "@app.function(volumes={\"/data\": volume}, mounts=[local_mount])\n",
    "def upload_data():\n",
    "    os.makedirs(\"/data\", exist_ok=True)\n",
    "\n",
    "    for file in Path(\"/source_data\").glob(\"*\"):\n",
    "        dest = f\"/data/{file.name}\"\n",
    "        if file.is_file():\n",
    "            shutil.copy(file, dest)\n",
    "            print(f\"Copied {file} to {dest}\")\n",
    "\n",
    "    print(\"\\nFiles in Modal volume:\")\n",
    "    for file in Path(\"/data\").glob(\"*\"):\n",
    "        print(f\" - {file}\")\n",
    "\n",
    "with app.run():\n",
    "    upload_data.remote()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f2d082d0-cd0f-4752-aeda-0d23d33915ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_286169/3241485202.py:12: DeprecationError: 2025-01-08: modal.Mount usage will soon be deprecated.\n",
      "\n",
      "Use image.add_local_dir instead, which is functionally and performance-wise equivalent.\n",
      "\n",
      "See https://modal.com/docs/guide/modal-1-0-migration for more details.\n",
      "\n",
      "  local_mount = Mount.from_local_dir(\"../data\", remote_path=\"/source_data\")\n"
     ]
    }
   ],
   "source": [
    "from modal import App, Volume, Mount\n",
    "from pathlib import Path\n",
    "import shutil, os\n",
    "\n",
    "# Define Modal app\n",
    "app = App(\"sr2-data-upload\")\n",
    "\n",
    "# Persistent Modal volume\n",
    "volume = Volume.from_name(\"sr2-data-volume\", create_if_missing=True)\n",
    "\n",
    "# Mount local ../data into the container at /source_data\n",
    "local_mount = Mount.from_local_dir(\"../data\", remote_path=\"/source_data\")\n",
    "\n",
    "# Function that runs inside Modal container\n",
    "@app.function(volumes={\"/data\": volume}, mounts=[local_mount])\n",
    "def upload_data():\n",
    "    os.makedirs(\"/data\", exist_ok=True)\n",
    "\n",
    "    # Copy files from mounted dir into the volume\n",
    "    for file in Path(\"/source_data\").glob(\"*\"):\n",
    "        dest = f\"/data/{file.name}\"\n",
    "        if file.is_file():\n",
    "            shutil.copy(file, dest)\n",
    "            print(f\"Copied {file} to {dest}\")\n",
    "\n",
    "    # Confirm files in the volume\n",
    "    print(\"\\nFiles in Modal volume:\")\n",
    "    for file in Path(\"/data\").glob(\"*\"):\n",
    "        print(f\" - {file}\")\n",
    "\n",
    "# Run the app inside the notebook\n",
    "with app.run():\n",
    "    upload_data.remote()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e945ba32-0827-4213-9ffc-ee69306d01c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modal import App, Volume, Image\n",
    "from pathlib import Path\n",
    "import shutil, os\n",
    "\n",
    "# Define Modal app\n",
    "app = App(\"sr3-data-upload\")\n",
    "\n",
    "# Persistent Modal volume\n",
    "volume = Volume.from_name(\"sr3-data-volume\", create_if_missing=True)\n",
    "\n",
    "# Define an image with your local ../data added at /source_data\n",
    "image = Image.debian_slim().add_local_dir(\"../data\", \"/source_data\")\n",
    "\n",
    "# Function that runs inside Modal container\n",
    "@app.function(volumes={\"/data\": volume}, image=image)\n",
    "def upload_data():\n",
    "    os.makedirs(\"/data\", exist_ok=True)\n",
    "\n",
    "    # Copy files from baked-in /source_data into the persistent volume\n",
    "    for file in Path(\"/source_data\").glob(\"*\"):\n",
    "        dest = f\"/data/{file.name}\"\n",
    "        if file.is_file():\n",
    "            shutil.copy(file, dest)\n",
    "            print(f\"Copied {file} to {dest}\")\n",
    "\n",
    "    # Confirm files in the volume\n",
    "    print(\"\\nFiles in Modal volume:\")\n",
    "    for file in Path(\"/data\").glob(\"*\"):\n",
    "        print(f\" - {file}\")\n",
    "\n",
    "# Run the app inside the notebook\n",
    "with app.run():\n",
    "    upload_data.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2c5aaba-16f4-4fba-91c0-f4195931f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modal import App, Volume, Image\n",
    "from pathlib import Path\n",
    "import boto3, shutil, os\n",
    "\n",
    "# Modal app\n",
    "app = App(\"sr-hybrid-upload\")\n",
    "\n",
    "# Persistent Modal volume\n",
    "volume = Volume.from_name(\"sr-hybrid-volume\", create_if_missing=True)\n",
    "\n",
    "# Image with boto3 for S3 + optional baked-in dataset\n",
    "image = (\n",
    "    Image.debian_slim()\n",
    "    .pip_install(\"boto3\")\n",
    "    # 👇 optional: freeze a dataset into the container at build time\n",
    "    .add_local_dir(\"../data\", \"/frozen_data\")\n",
    ")\n",
    "\n",
    "\n",
    "@app.function(volumes={\"/data\": volume}, image=image)\n",
    "def upload_data(local_files: dict = None, s3_bucket: str = None, s3_prefix: str = None, use_frozen: bool = False):\n",
    "    \"\"\"\n",
    "    Uploads data into the Modal volume.\n",
    "    - local_files: development mode, uploads directly from host\n",
    "    - s3_bucket + s3_prefix: production mode, pulls from S3\n",
    "    - use_frozen=True: frozen dataset baked into the container image\n",
    "    \"\"\"\n",
    "    os.makedirs(\"/data\", exist_ok=True)\n",
    "\n",
    "    if local_files:\n",
    "        # Dev mode\n",
    "        for name, content in local_files.items():\n",
    "            dest = f\"/data/{name}\"\n",
    "            with open(dest, \"wb\") as f:\n",
    "                f.write(content)\n",
    "            print(f\"[DEV] Copied {name} -> {dest}\")\n",
    "\n",
    "    elif s3_bucket and s3_prefix:\n",
    "        # Prod mode\n",
    "        s3 = boto3.client(\"s3\")\n",
    "        result = s3.list_objects_v2(Bucket=s3_bucket, Prefix=s3_prefix)\n",
    "\n",
    "        for obj in result.get(\"Contents\", []):\n",
    "            key = obj[\"Key\"]\n",
    "            filename = os.path.basename(key)\n",
    "            dest = f\"/data/{filename}\"\n",
    "\n",
    "            s3.download_file(s3_bucket, key, dest)\n",
    "            print(f\"[PROD] Downloaded s3://{s3_bucket}/{key} -> {dest}\")\n",
    "\n",
    "    elif use_frozen:\n",
    "        # Frozen dataset baked in at build time\n",
    "        for file in Path(\"/frozen_data\").glob(\"*\"):\n",
    "            dest = f\"/data/{file.name}\"\n",
    "            if file.is_file():\n",
    "                shutil.copy(file, dest)\n",
    "                print(f\"[FROZEN] Copied {file} -> {dest}\")\n",
    "\n",
    "    else:\n",
    "        print(\"⚠️ No data source provided. Pass local_files, s3_bucket+s3_prefix, or use_frozen=True.\")\n",
    "\n",
    "    # Confirm files\n",
    "    print(\"\\nFiles in Modal volume:\")\n",
    "    for file in Path(\"/data\").glob(\"*\"):\n",
    "        print(f\" - {file}\")\n",
    "\n",
    "\n",
    "# === Notebook/CLI Helpers ===\n",
    "\n",
    "def run_upload_local(path=\"../data\"):\n",
    "    \"\"\"Upload local files (dev mode).\"\"\"\n",
    "    local_files = {}\n",
    "    for file in Path(path).glob(\"*\"):\n",
    "        if file.is_file():\n",
    "            local_files[file.name] = file.read_bytes()\n",
    "\n",
    "    with app.run():\n",
    "        upload_data.remote(local_files=local_files)\n",
    "\n",
    "\n",
    "def run_upload_s3(bucket, prefix):\n",
    "    \"\"\"Upload from S3 (prod mode).\"\"\"\n",
    "    with app.run():\n",
    "        upload_data.remote(s3_bucket=bucket, s3_prefix=prefix)\n",
    "\n",
    "\n",
    "def run_upload_frozen():\n",
    "    \"\"\"Upload baked-in dataset (frozen mode).\"\"\"\n",
    "    with app.run():\n",
    "        upload_data.remote(use_frozen=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0447cfaf-819e-4b8f-a781-7291c8b678df",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_upload_frozen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2f5cf82-f93b-4c51-b0c8-b8c4b1ed5dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import File, UploadFile, Form, HTTPException\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c88c125d-2867-4fd9-bb91-3e9d861478dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modal import App, Volume, Image\n",
    "from pathlib import Path\n",
    "import boto3, shutil, os\n",
    "\n",
    "# Modal app\n",
    "app = App(\"sr-hybrid-upload-app\")\n",
    "\n",
    "# Persistent Modal volume\n",
    "volume = Volume.from_name(\"sr-hybrid-app-volume\", create_if_missing=True)\n",
    "\n",
    "# Image with boto3 for S3 + optional baked-in dataset + baked-in model artifacts\n",
    "image = (\n",
    "    Image.debian_slim()\n",
    "    .pip_install(\"boto3\")\n",
    "    .add_local_dir(\"../data\", \"/frozen_data\")               # dataset (optional frozen)\n",
    "    .add_local_dir(\"../model\", \"/frozen_model\")        # model artifacts (optional frozen)\n",
    ")\n",
    "\n",
    "\n",
    "@app.function(volumes={\"/data\": volume}, image=image)\n",
    "def upload_all(local_dirs: dict = None, s3_bucket: str = None, s3_prefix: str = None, use_frozen: bool = False):\n",
    "    \"\"\"\n",
    "    Uploads training data + model artifacts into the Modal volume.\n",
    "\n",
    "    - local_dirs: dict of {\"remote_subdir\": \"local_path\"} (dev mode)\n",
    "    - s3_bucket + s3_prefix: fetch from S3 (prod mode)\n",
    "    - use_frozen: copy pre-baked datasets + models\n",
    "    \"\"\"\n",
    "    os.makedirs(\"/data\", exist_ok=True)\n",
    "\n",
    "    if local_dirs:\n",
    "        # Dev mode\n",
    "        for subdir, local_path in local_dirs.items():\n",
    "            dest_dir = Path(f\"/data/{subdir}\")\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            for file in Path(local_path).glob(\"*\"):\n",
    "                if file.is_file():\n",
    "                    shutil.copy(file, dest_dir / file.name)\n",
    "                    print(f\"[DEV] Copied {file} -> {dest_dir / file.name}\")\n",
    "\n",
    "    elif s3_bucket and s3_prefix:\n",
    "        # Prod mode (fetching from S3)\n",
    "        s3 = boto3.client(\"s3\")\n",
    "        result = s3.list_objects_v2(Bucket=s3_bucket, Prefix=s3_prefix)\n",
    "\n",
    "        for obj in result.get(\"Contents\", []):\n",
    "            key = obj[\"Key\"]\n",
    "            filename = os.path.basename(key)\n",
    "            subdir = os.path.dirname(key).split(\"/\")[-1]  # e.g. \"model\" or \"data\"\n",
    "            dest_dir = Path(f\"/data/{subdir}\")\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            dest = dest_dir / filename\n",
    "            s3.download_file(s3_bucket, key, str(dest))\n",
    "            print(f\"[PROD] Downloaded s3://{s3_bucket}/{key} -> {dest}\")\n",
    "\n",
    "    elif use_frozen:\n",
    "        # Frozen mode (both datasets + model artifacts baked in)\n",
    "        for folder, frozen_path in [(\"data\", \"/frozen_data\"), (\"model\", \"/frozen_model\")]:\n",
    "            dest_dir = Path(f\"/data/{folder}\")\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            for file in Path(frozen_path).glob(\"*\"):\n",
    "                if file.is_file():\n",
    "                    shutil.copy(file, dest_dir / file.name)\n",
    "                    print(f\"[FROZEN] Copied {file} -> {dest_dir / file.name}\")\n",
    "\n",
    "    else:\n",
    "        print(\"⚠️ No source provided. Pass local_dirs, or s3_bucket+s3_prefix, or use_frozen=True.\")\n",
    "\n",
    "    # Confirm\n",
    "    print(\"\\nFiles now in Modal volume:\")\n",
    "    for file in Path(\"/data\").rglob(\"*\"):\n",
    "        print(f\" - {file}\")\n",
    "\n",
    "\n",
    "# === Notebook/CLI helpers ===\n",
    "\n",
    "def run_upload_local():\n",
    "    \"\"\"Upload local dataset + model artifacts (dev mode).\"\"\"\n",
    "    local_dirs = {\n",
    "        \"data\": \"../data\",                  # training data\n",
    "        \"model\": \"../model\"            # model artifacts (pkl, json, etc.)\n",
    "    }\n",
    "    with app.run():\n",
    "        upload_all.remote(local_dirs=local_dirs)\n",
    "\n",
    "\n",
    "def run_upload_s3(bucket, prefix):\n",
    "    \"\"\"Upload from S3 (prod mode).\"\"\"\n",
    "    with app.run():\n",
    "        upload_all.remote(s3_bucket=bucket, s3_prefix=prefix)\n",
    "\n",
    "\n",
    "def run_upload_frozen():\n",
    "    \"\"\"Upload frozen dataset + model artifacts (frozen mode).\"\"\"\n",
    "    with app.run():\n",
    "        upload_all.remote(use_frozen=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66101c85-b522-46af-b18d-54842ea16f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_upload_frozen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1024bfd6-b786-4774-9689-0f7c41f3860a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.pkl  model_features.json\n"
     ]
    }
   ],
   "source": [
    "!ls ../model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9ae09-9ad0-4bfc-b676-92d2a0ba10b2",
   "metadata": {},
   "source": [
    "## Model Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5e612f4-0862-4971-9940-300a44d7aa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastapi import File, UploadFile, Form, HTTPException\n",
    "import io\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Create app definition\n",
    "app = modal.App(\"sr-hybrid-sales-api\")\n",
    "\n",
    "# Define base image with all dependencies\n",
    "base_image = (modal.Image.debian_slim()\n",
    "        .pip_install(\"pydantic==1.10.8\")        \n",
    "        .pip_install(\"fastapi==0.95.2\")         \n",
    "        .pip_install(\"uvicorn==0.22.0\")         \n",
    "        .pip_install([                         \n",
    "            \"xgboost==1.7.6\",\n",
    "            \"scikit-learn==1.3.1\",\n",
    "            \"pandas\",\n",
    "            \"numpy\",\n",
    "        ]))\n",
    "\n",
    "# Create volume to access data (changed volume name)\n",
    "data_volume = modal.Volume.from_name(\"sr-hybrid-app-volume\")\n",
    "\n",
    "# Simple health endpoint\n",
    "@app.function(image=base_image)\n",
    "@modal.fastapi_endpoint(method=\"GET\")\n",
    "def health():\n",
    "   \"\"\"Health check endpoint to verify the API is running\"\"\"\n",
    "   return {\"status\": \"healthy\", \"service\": \"sr-hybrid-sales-api\"}\n",
    "\n",
    "# Function to load the existing model\n",
    "@app.function(image=base_image, volumes={\"/data\": data_volume})\n",
    "def serve_model():\n",
    "   \"\"\"Load the existing trained model from pickle\"\"\"\n",
    "   import pickle\n",
    "   import os\n",
    "   \n",
    "   model_path = \"/data/model/model.pkl\"\n",
    "   \n",
    "   try:\n",
    "       if os.path.exists(model_path):\n",
    "           print(f\"Loading existing model from {model_path}\")\n",
    "           with open(model_path, 'rb') as f:\n",
    "               model = pickle.load(f)\n",
    "           print(\"Model loaded successfully!\")\n",
    "           return model\n",
    "       else:\n",
    "           raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "           \n",
    "   except Exception as e:\n",
    "       import traceback\n",
    "       print(f\"Error loading model: {str(e)}\")\n",
    "       print(traceback.format_exc())\n",
    "       raise\n",
    "\n",
    "# Function to load model features\n",
    "@app.function(image=base_image, volumes={\"/data\": data_volume})\n",
    "def load_model_features():\n",
    "   \"\"\"Load the expected model features from JSON\"\"\"\n",
    "   import json\n",
    "   \n",
    "   features_path = \"/data/model/model_features.json\"\n",
    "   \n",
    "   try:\n",
    "       if os.path.exists(features_path):\n",
    "           with open(features_path, 'r') as f:\n",
    "               features = json.load(f)\n",
    "           print(f\"Loaded {len(features)} expected features\")\n",
    "           return features\n",
    "       else:\n",
    "           raise FileNotFoundError(f\"Features file not found at {features_path}\")\n",
    "           \n",
    "   except Exception as e:\n",
    "       import traceback\n",
    "       print(f\"Error loading features: {str(e)}\")\n",
    "       print(traceback.format_exc())\n",
    "       raise\n",
    "\n",
    "# CSV upload endpoint with new preprocessing pipeline\n",
    "@app.function(image=base_image, volumes={\"/data\": data_volume})\n",
    "@modal.fastapi_endpoint(method=\"POST\")\n",
    "async def predict_csv(file: UploadFile = File(...)):\n",
    "    \"\"\"API endpoint for batch predictions from a CSV file using existing model\"\"\"\n",
    "    import pandas as pd\n",
    "    import io\n",
    "    import pickle\n",
    "    import os\n",
    "    import traceback\n",
    "    from pathlib import Path\n",
    "    \n",
    "    try:\n",
    "        # Load the pre-trained model\n",
    "        model = serve_model.remote()\n",
    "        print(\"Model loaded successfully\")\n",
    "        \n",
    "        # Load expected features\n",
    "        expected_features = load_model_features.remote()\n",
    "        print(f\"Expected features loaded: {len(expected_features)} features\")\n",
    "        \n",
    "        # Read uploaded CSV file content\n",
    "        contents = await file.read()\n",
    "        \n",
    "        # Parse CSV data\n",
    "        try:\n",
    "            test_df = pd.read_csv(io.BytesIO(contents))\n",
    "            print(f\"Test data shape: {test_df.shape}\")\n",
    "            print(f\"Test data columns: {test_df.columns.tolist()}\")\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Failed to parse uploaded CSV: {str(e)}\"\n",
    "            }\n",
    "        \n",
    "        # Load demographic data for merging\n",
    "        demographics_path = \"/data/data/zipcode_demographics.csv\"\n",
    "        if os.path.exists(demographics_path):\n",
    "            demo_df = pd.read_csv(demographics_path)\n",
    "            print(f\"Demographics data shape: {demo_df.shape}\")\n",
    "            \n",
    "            # Merge test data with demographics\n",
    "            # Assuming 'zipcode' is the common column - adjust if different\n",
    "            if 'zipcode' in test_df.columns and 'zipcode' in demo_df.columns:\n",
    "                merged_df = pd.merge(test_df, demo_df, on='zipcode', how='left')\n",
    "                print(f\"Merged data shape: {merged_df.shape}\")\n",
    "            else:\n",
    "                print(\"Warning: zipcode column not found, using test data as-is\")\n",
    "                merged_df = test_df.copy()\n",
    "        else:\n",
    "            print(\"Warning: Demographics file not found, using test data as-is\")\n",
    "            merged_df = test_df.copy()\n",
    "        \n",
    "        # Select only the expected features\n",
    "        available_features = [col for col in expected_features if col in merged_df.columns]\n",
    "        missing_features = [col for col in expected_features if col not in merged_df.columns]\n",
    "        \n",
    "        if missing_features:\n",
    "            print(f\"Warning: Missing features: {missing_features}\")\n",
    "            # Add missing features with default values (0 or mean/median)\n",
    "            for feature in missing_features:\n",
    "                merged_df[feature] = 0  # or use a more sophisticated default\n",
    "        \n",
    "        # Select the exact features expected by the model\n",
    "        feature_df = merged_df[expected_features].copy()\n",
    "        print(f\"Final feature matrix shape: {feature_df.shape}\")\n",
    "        \n",
    "        # Handle any remaining missing values\n",
    "        feature_df = feature_df.fillna(0)  # or use more sophisticated imputation\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = model.predict(feature_df)\n",
    "        print(f\"Predictions shape: {predictions.shape}\")\n",
    "        \n",
    "        # Return predictions as a list\n",
    "        return predictions.tolist()\n",
    "            \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": f\"Error processing CSV: {str(e)}\",\n",
    "            \"traceback\": traceback.format_exc()\n",
    "        }\n",
    "\n",
    "@app.local_entrypoint()\n",
    "def main():\n",
    "   \"\"\"Local entrypoint for testing the API\"\"\"\n",
    "   print(\"Starting sr-hybrid-sales-api...\")\n",
    "   \n",
    "   # Pre-load the model to ensure it exists\n",
    "   print(\"Preparing model...\")\n",
    "   serve_model.remote()\n",
    "   print(\"Model preparation complete!\")\n",
    "   \n",
    "   print(\"\\nAPI is ready for use at:\")\n",
    "   print(\"- Health check: https://flexible-functions-ai--sr-hybrid-sales-api-health.modal.run\")\n",
    "   print(\"- CSV predictions: https://flexible-functions-ai--sr-hybrid-sales-api-predict-csv.modal.run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa99abc-7143-4963-b0fd-f767a83b4753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the app\n",
    "app.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03af4ae1-a7d4-4467-95ae-3644e0257116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modal API Tester\n",
      "Remember to update the URLs with your actual deployed endpoints!\n",
      "\n",
      "⚠️  IMPORTANT: Update these URLs with your actual deployment URLs:\n",
      "Current health URL: https://flexible-functions-ai--sr-hybrid-sales-api-health.modal.run\n",
      "Current predict URL: {https://flexible-functions-ai--sr-hybrid-sales-api-predict-csv.modal.run\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "class ModalAPITester:\n",
    "    def __init__(self, base_url=None):\n",
    "        \"\"\"\n",
    "        Initialize the tester with base URL\n",
    "        You'll need to update these URLs after deployment\n",
    "        \"\"\"\n",
    "        if base_url:\n",
    "            self.health_url = f\"{https://flexible-functions-ai--sr-hybrid-sales-api}-health.modal.run\"\n",
    "            self.predict_url = f\"{https://flexible-functions-ai--sr-hybrid-sales-api}-predict-csv.modal.run\"\n",
    "        else:\n",
    "            # You'll need to replace these with your actual deployed URLs\n",
    "            self.health_url = \"https://flexible-functions-ai--sr-hybrid-sales-api-health.modal.run\"\n",
    "            self.predict_url = \"{https://flexible-functions-ai--sr-hybrid-sales-api-predict-csv.modal.run\"\n",
    "    \n",
    "    def test_health_endpoint(self):\n",
    "        \"\"\"Test the health check endpoint\"\"\"\n",
    "        print(\"=\" * 50)\n",
    "        print(\"Testing Health Endpoint\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(self.health_url, timeout=10)\n",
    "            \n",
    "            print(f\"Status Code: {response.status_code}\")\n",
    "            print(f\"Response: {response.json()}\")\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                print(\"✅ Health endpoint is working!\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"❌ Health endpoint failed!\")\n",
    "                return False\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"❌ Error connecting to health endpoint: {str(e)}\")\n",
    "            print(\"Make sure your Modal app is deployed and the URL is correct\")\n",
    "            return False\n",
    "    \n",
    "    def test_predict_endpoint(self, csv_file_path=None):\n",
    "        \"\"\"Test the CSV prediction endpoint\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"Testing Prediction Endpoint\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Default test data\n",
    "        if csv_file_path is None:\n",
    "            csv_file_path = self.create_test_csv()\n",
    "        \n",
    "        try:\n",
    "            # Check if file exists\n",
    "            if not Path(csv_file_path).exists():\n",
    "                print(f\"❌ Test file not found: {csv_file_path}\")\n",
    "                return False\n",
    "            \n",
    "            print(f\"Using test file: {csv_file_path}\")\n",
    "            \n",
    "            # Read and display file info\n",
    "            test_df = pd.read_csv(csv_file_path)\n",
    "            print(f\"Test data shape: {test_df.shape}\")\n",
    "            print(f\"Test data columns: {test_df.columns.tolist()}\")\n",
    "            print(f\"First few rows:\\n{test_df.head()}\")\n",
    "            \n",
    "            # Prepare the file for upload\n",
    "            with open(csv_file_path, 'rb') as f:\n",
    "                files = {'file': ('test_data.csv', f, 'text/csv')}\n",
    "                \n",
    "                print(f\"\\nSending request to: {self.predict_url}\")\n",
    "                print(\"This might take a moment...\")\n",
    "                \n",
    "                # Make the request\n",
    "                response = requests.post(\n",
    "                    self.predict_url, \n",
    "                    files=files,\n",
    "                    timeout=60  # Increase timeout for model inference\n",
    "                )\n",
    "            \n",
    "            print(f\"Status Code: {response.status_code}\")\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                try:\n",
    "                    result = response.json()\n",
    "                    \n",
    "                    if isinstance(result, list):\n",
    "                        # Direct predictions\n",
    "                        predictions = result\n",
    "                        print(f\"✅ Predictions received!\")\n",
    "                        print(f\"Number of predictions: {len(predictions)}\")\n",
    "                        print(f\"First 5 predictions: {predictions[:5]}\")\n",
    "                        print(f\"Prediction range: {min(predictions):.2f} to {max(predictions):.2f}\")\n",
    "                        return True\n",
    "                        \n",
    "                    elif isinstance(result, dict) and result.get('success') == False:\n",
    "                        # Error response\n",
    "                        print(f\"❌ API returned error: {result.get('error')}\")\n",
    "                        if 'traceback' in result:\n",
    "                            print(f\"Traceback: {result['traceback']}\")\n",
    "                        return False\n",
    "                        \n",
    "                    else:\n",
    "                        # Structured response\n",
    "                        print(f\"Response: {result}\")\n",
    "                        return True\n",
    "                        \n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"❌ Could not parse JSON response: {response.text}\")\n",
    "                    return False\n",
    "            else:\n",
    "                print(f\"❌ Request failed with status {response.status_code}\")\n",
    "                print(f\"Response: {response.text}\")\n",
    "                return False\n",
    "                \n",
    "        except requests.exceptions.Timeout:\n",
    "            print(\"❌ Request timed out. The model might be taking too long to respond.\")\n",
    "            return False\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"❌ Error making request: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def create_test_csv(self):\n",
    "        \"\"\"Create a simple test CSV if none provided\"\"\"\n",
    "        test_data = {\n",
    "            'bedrooms': [3, 4, 2, 5],\n",
    "            'bathrooms': [2.0, 3.0, 1.5, 2.5],\n",
    "            'sqft_living': [1500, 2000, 1200, 2500],\n",
    "            'sqft_lot': [5000, 6000, 4000, 7000],\n",
    "            'floors': [1, 2, 1, 2],\n",
    "            'zipcode': [98001, 98002, 98003, 98004]  # Assuming these exist in demographics\n",
    "        }\n",
    "        \n",
    "        test_df = pd.DataFrame(test_data)\n",
    "        test_file = 'test_predictions.csv'\n",
    "        test_df.to_csv(test_file, index=False)\n",
    "        \n",
    "        print(f\"Created test CSV: {test_file}\")\n",
    "        return test_file\n",
    "    \n",
    "    def run_full_test(self, csv_file_path=None):\n",
    "        \"\"\"Run complete test suite\"\"\"\n",
    "        print(\"🚀 Starting Modal API Tests\")\n",
    "        print(f\"Health URL: {self.health_url}\")\n",
    "        print(f\"Predict URL: {self.predict_url}\")\n",
    "        \n",
    "        # Test 1: Health check\n",
    "        health_passed = self.test_health_endpoint()\n",
    "        \n",
    "        if not health_passed:\n",
    "            print(\"\\n❌ Health check failed. Skipping prediction test.\")\n",
    "            return False\n",
    "        \n",
    "        # Test 2: Prediction endpoint\n",
    "        predict_passed = self.test_predict_endpoint(csv_file_path)\n",
    "        \n",
    "        # Summary\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"TEST SUMMARY\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Health Endpoint: {'✅ PASS' if health_passed else '❌ FAIL'}\")\n",
    "        print(f\"Predict Endpoint: {'✅ PASS' if predict_passed else '❌ FAIL'}\")\n",
    "        \n",
    "        if health_passed and predict_passed:\n",
    "            print(\"\\n🎉 All tests passed! Your API is working correctly.\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"\\n😞 Some tests failed. Check the errors above.\")\n",
    "            return False\n",
    "\n",
    "# Usage examples:\n",
    "def test_with_default_data():\n",
    "    \"\"\"Test with automatically generated data\"\"\"\n",
    "    tester = ModalAPITester()\n",
    "    # Update URLs after deployment\n",
    "    tester.health_url = \"https://flexible-functions-ai--sr-hybrid-sales-api-health.modal.run/\"\n",
    "    tester.predict_url = \"https://flexible-functions-ai--sr-hybrid-sales-api-predict-csv.modal.run\"\n",
    "    \n",
    "    return tester.run_full_test()\n",
    "\n",
    "def test_with_your_data():\n",
    "    \"\"\"Test with your actual test data\"\"\"\n",
    "    tester = ModalAPITester()\n",
    "    # Update URLs after deployment\n",
    "    tester.health_url = \"https://flexible-functions-ai--sr-hybrid-sales-api-health.modal.run/\"\n",
    "    tester.predict_url = \"https://flexible-functions-ai--sr-hybrid-sales-api-predict-csv.modal.run\"\n",
    "    \n",
    "    # Use your actual test file\n",
    "    csv_file = \"../data/future_unseen_examples.csv\"  # Adjust path as needed\n",
    "    return tester.run_full_test(csv_file)\n",
    "\n",
    "def quick_test():\n",
    "    \"\"\"Quick test function for notebook use\"\"\"\n",
    "    # Replace these URLs with your actual deployment URLs\n",
    "    health_url = \"https://flexible-functions-ai--sr-hybrid-sales-api-health.modal.run/\"\n",
    "    predict_url = \"https://flexible-functions-ai--sr-hybrid-sales-api-predict-csv.modal.run\"\n",
    "    \n",
    "    tester = ModalAPITester()\n",
    "    tester.health_url = health_url\n",
    "    tester.predict_url = predict_url\n",
    "    \n",
    "    return tester.run_full_test()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the test\n",
    "    print(\"Modal API Tester\")\n",
    "    print(\"Remember to update the URLs with your actual deployed endpoints!\")\n",
    "    \n",
    "    # Create tester instance\n",
    "    tester = ModalAPITester()\n",
    "    \n",
    "    # You MUST update these URLs after deployment\n",
    "    print(\"\\n⚠️  IMPORTANT: Update these URLs with your actual deployment URLs:\")\n",
    "    print(f\"Current health URL: {tester.health_url}\")\n",
    "    print(f\"Current predict URL: {tester.predict_url}\")\n",
    "    \n",
    "    # Uncomment to run with default test data:\n",
    "    #test_with_default_data()\n",
    "    \n",
    "    # Uncomment to run with your actual data:\n",
    "    # test_with_your_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a50e528-4f19-4c30-9d53-516115961e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Modal API Tests\n",
      "Health URL: https://flexible-functions-ai--sr-hybrid-sales-api-health.modal.run/\n",
      "Predict URL: https://flexible-functions-ai--sr-hybrid-sales-api-predict-csv.modal.run\n",
      "==================================================\n",
      "Testing Health Endpoint\n",
      "==================================================\n",
      "❌ Error connecting to health endpoint: HTTPSConnectionPool(host='flexible-functions-ai--sr-hybrid-sales-api-health.modal.run', port=443): Read timed out. (read timeout=10)\n",
      "Make sure your Modal app is deployed and the URL is correct\n",
      "\n",
      "❌ Health check failed. Skipping prediction test.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_with_your_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6ef30b-825f-4bcf-87bb-050044f56944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedaf292-2565-40e0-b312-9d16869f2be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b9b0c-087c-4a12-830f-db10d95dd303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e982c3e0-1c62-43dd-ba57-60c54ee7ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modal import App, Volume, Image\n",
    "from fastapi import UploadFile, File, HTTPException\n",
    "import io, json, joblib, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Modal setup ===\n",
    "app = App(\"sr-house-price-api\")\n",
    "\n",
    "volume = Volume.from_name(\"sr-hybrid-app-volume\")\n",
    "\n",
    "image = (\n",
    "    Image.debian_slim()\n",
    "    .pip_install(\n",
    "        \"fastapi\",\n",
    "        \"uvicorn\",\n",
    "        \"scikit-learn\",\n",
    "        \"pandas\",\n",
    "        \"numpy\",\n",
    "        \"joblib\",\n",
    "        \"bentoml\",          # if you want Bento validation\n",
    "        \"dash\",             # if you plan to expose a Dash UI alongside\n",
    "    )\n",
    ")\n",
    "\n",
    "# === Globals cached in container ===\n",
    "MODEL = None\n",
    "FEATURES = None\n",
    "DEMOGRAPHICS = None\n",
    "\n",
    "\n",
    "def _load_artifacts():\n",
    "    \"\"\"Load model, features, demographics into globals (once per container).\"\"\"\n",
    "    global MODEL, FEATURES, DEMOGRAPHICS\n",
    "\n",
    "    if MODEL is not None:\n",
    "        return  # already loaded\n",
    "\n",
    "    model_path = Path(\"/data/model/model.pkl\")\n",
    "    features_path = Path(\"/data/model/model_features.json\")\n",
    "    demo_path = Path(\"/data/data/demographics.csv\")\n",
    "\n",
    "    if not model_path.exists() or not features_path.exists():\n",
    "        raise RuntimeError(\"Model artifacts missing in Modal volume (/data/model/*).\")\n",
    "\n",
    "    MODEL = joblib.load(model_path)\n",
    "    with open(features_path) as f:\n",
    "        FEATURES = json.load(f)\n",
    "\n",
    "    if not demo_path.exists():\n",
    "        raise RuntimeError(\"Demographics file missing in /data/data/demographics.csv\")\n",
    "    DEMOGRAPHICS = pd.read_csv(demo_path)\n",
    "\n",
    "\n",
    "def _prepare_feature_vector(zipcode: str, extra_inputs: dict):\n",
    "    \"\"\"Return a feature vector aligned with model features.\"\"\"\n",
    "    row = DEMOGRAPHICS.loc[DEMOGRAPHICS[\"zipcode\"] == str(zipcode)]\n",
    "    if row.empty:\n",
    "        raise ValueError(f\"Zipcode {zipcode} not found in demographics.\")\n",
    "    demo_row = row.iloc[0].to_dict()\n",
    "\n",
    "    merged = {**demo_row, **(extra_inputs or {})}\n",
    "\n",
    "    vector = []\n",
    "    for feat in FEATURES:\n",
    "        if feat not in merged:\n",
    "            raise ValueError(f\"Missing required feature: {feat}\")\n",
    "        vector.append(merged[feat])\n",
    "    return vector\n",
    "\n",
    "\n",
    "# === Endpoints ===\n",
    "\n",
    "@app.function(image=image, volumes={\"/data\": volume})\n",
    "@modal.fastapi_endpoint(method=\"GET\")\n",
    "def health():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return {\"status\": \"healthy\", \"service\": \"sr-house-price-api\"}\n",
    "\n",
    "\n",
    "@app.function(image=image, volumes={\"/data\": volume})\n",
    "@modal.fastapi_endpoint(method=\"POST\")\n",
    "async def predict_single(request: dict):\n",
    "    \"\"\"\n",
    "    Single prediction endpoint.\n",
    "    Example input:\n",
    "    {\n",
    "        \"zipcode\": \"98109\",\n",
    "        \"extra_inputs\": {\"sqft\": 1500, \"num_bedrooms\": 3}\n",
    "    }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        _load_artifacts()\n",
    "        zipcode = request.get(\"zipcode\")\n",
    "        if not zipcode:\n",
    "            raise ValueError(\"zipcode is required\")\n",
    "\n",
    "        vector = _prepare_feature_vector(zipcode, request.get(\"extra_inputs\"))\n",
    "        pred = MODEL.predict([vector])[0]\n",
    "        return {\"prediction\": float(pred)}\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=str(e))\n",
    "\n",
    "\n",
    "@app.function(image=image, volumes={\"/data\": volume})\n",
    "@modal.fastapi_endpoint(method=\"POST\")\n",
    "async def predict_batch(file: UploadFile = File(...)):\n",
    "    \"\"\"\n",
    "    Batch prediction endpoint.\n",
    "    CSV must include 'zipcode' column plus any extra input features.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        _load_artifacts()\n",
    "\n",
    "        contents = await file.read()\n",
    "        df = pd.read_csv(io.BytesIO(contents))\n",
    "\n",
    "        if \"zipcode\" not in df.columns:\n",
    "            raise ValueError(\"CSV must include 'zipcode' column\")\n",
    "\n",
    "        preds = []\n",
    "        for _, row in df.iterrows():\n",
    "            try:\n",
    "                vector = _prepare_feature_vector(\n",
    "                    row[\"zipcode\"], row.drop(\"zipcode\").to_dict()\n",
    "                )\n",
    "                pred = MODEL.predict([vector])[0]\n",
    "                preds.append({\"zipcode\": row[\"zipcode\"], \"prediction\": float(pred)})\n",
    "            except Exception as inner_e:\n",
    "                preds.append({\"zipcode\": row[\"zipcode\"], \"error\": str(inner_e)})\n",
    "\n",
    "        return preds\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=str(e))\n",
    "\n",
    "\n",
    "# === Local entrypoint for testing ===\n",
    "@app.local_entrypoint()\n",
    "def main():\n",
    "    print(\"🏡 House Price Prediction API\")\n",
    "    print(\"Health check: https://<your-app-name>--sr-house-price-api-health.modal.run\")\n",
    "    print(\"Single prediction: https://<your-app-name>--sr-house-price-api-predict-single.modal.run\")\n",
    "    print(\"Batch prediction: https://<your-app-name>--sr-house-price-api-predict-batch.modal.run\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c82a3057-2a15-45d4-92ec-f9be8416bc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.Blocking_AsyncGeneratorContextManager at 0x7f17bb91c920>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62e906e5-c638-4cf9-a2a5-67c00e020354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<modal.app.App at 0x7f17b2d39790>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c5cda86-92f3-401c-801a-29021c2dbb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_105302/2105608628.py:65: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator('yr_renovated')\n",
      "/tmp/ipykernel_105302/2105608628.py:291: DeprecationError: 2025-02-24: We have renamed several parameters related to autoscaling. Please update your code to use the following new names:\n",
      "\n",
      "- container_idle_timeout -> scaledown_window\n",
      "\n",
      "See https://modal.com/docs/guide/modal-1-0-migration for more details.\n",
      "  @app.function(\n",
      "/tmp/ipykernel_105302/2105608628.py:308: DeprecationError: 2025-02-24: We have renamed several parameters related to autoscaling. Please update your code to use the following new names:\n",
      "\n",
      "- container_idle_timeout -> scaledown_window\n",
      "\n",
      "See https://modal.com/docs/guide/modal-1-0-migration for more details.\n",
      "  @app.function(\n",
      "<frozen posixpath>:82: RuntimeWarning: coroutine 'run_modal_api' was never awaited\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/tmp/ipykernel_105302/2105608628.py:338: DeprecationError: 2025-02-24: We have renamed several parameters related to autoscaling. Please update your code to use the following new names:\n",
      "\n",
      "- container_idle_timeout -> scaledown_window\n",
      "\n",
      "See https://modal.com/docs/guide/modal-1-0-migration for more details.\n",
      "  @app.function(\n",
      "/tmp/ipykernel_105302/2105608628.py:368: DeprecationError: 2025-02-24: We have renamed several parameters related to autoscaling. Please update your code to use the following new names:\n",
      "\n",
      "- container_idle_timeout -> scaledown_window\n",
      "\n",
      "See https://modal.com/docs/guide/modal-1-0-migration for more details.\n",
      "  @app.function(\n",
      "/tmp/ipykernel_105302/2105608628.py:410: DeprecationError: 2025-02-24: We have renamed several parameters related to autoscaling. Please update your code to use the following new names:\n",
      "\n",
      "- container_idle_timeout -> scaledown_window\n",
      "\n",
      "See https://modal.com/docs/guide/modal-1-0-migration for more details.\n",
      "  @app.function(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Deploying Real Estate Prediction API...\n",
      "============================================================\n",
      "\n",
      "Pre-loading model and data...\n"
     ]
    },
    {
     "ename": "RemoteError",
     "evalue": "Image build for im-GhsUxCwkXHCE5fo6Fd59Bg failed with the exception:\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRemoteError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 462\u001b[39m\n\u001b[32m    459\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/synchronicity/synchronizer.py:592\u001b[39m, in \u001b[36mSynchronizer._wrap_proxy_method.<locals>.proxy_method\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    590\u001b[39m instance = \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m[synchronizer_self._original_attr]\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m UserCodeException \u001b[38;5;28;01mas\u001b[39;00m uc_exc:\n\u001b[32m    594\u001b[39m     uc_exc.exc.__suppress_context__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/synchronicity/synchronizer.py:482\u001b[39m, in \u001b[36mSynchronizer._wrap_callable.<locals>.f_wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m     kwargs = \u001b[38;5;28mself\u001b[39m._translate_in(kwargs)\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# Call the function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m res = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# Figure out if this is a coroutine or something\u001b[39;00m\n\u001b[32m    485\u001b[39m is_coroutine = inspect.iscoroutine(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/modal/app.py:73\u001b[39m, in \u001b[36m_LocalEntrypoint.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Any:\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraw_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 444\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPre-loading model and data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    443\u001b[39m \u001b[38;5;66;03m# Trigger model loading\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m444\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhealth_status\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mhealth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mHealth check: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mhealth_status\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/synchronicity/synchronizer.py:592\u001b[39m, in \u001b[36mSynchronizer._wrap_proxy_method.<locals>.proxy_method\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    590\u001b[39m instance = \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m[synchronizer_self._original_attr]\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m UserCodeException \u001b[38;5;28;01mas\u001b[39;00m uc_exc:\n\u001b[32m    594\u001b[39m     uc_exc.exc.__suppress_context__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/synchronicity/combined_types.py:29\u001b[39m, in \u001b[36mFunctionWithAio.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m UserCodeException \u001b[38;5;28;01mas\u001b[39;00m uc_exc:\n\u001b[32m     28\u001b[39m     uc_exc.exc.__suppress_context__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m uc_exc.exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/contextlib.py:210\u001b[39m, in \u001b[36m_AsyncGeneratorContextManager.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m anext(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/modal/app.py:387\u001b[39m, in \u001b[36m_App.run\u001b[39m\u001b[34m(self, client, show_progress, detach, interactive, environment_name)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m show_progress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    385\u001b[39m     deprecation_warning((\u001b[32m2024\u001b[39m, \u001b[32m11\u001b[39m, \u001b[32m20\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33m`show_progress=False` is deprecated (and has no effect)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m _run_app(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m, client=client, detach=detach, interactive=interactive, environment_name=environment_name\n\u001b[32m    389\u001b[39m ):\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/contextlib.py:210\u001b[39m, in \u001b[36m_AsyncGeneratorContextManager.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m anext(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/modal/runner.py:347\u001b[39m, in \u001b[36m_run_app\u001b[39m\u001b[34m(app, client, detach, environment_name, interactive)\u001b[39m\n\u001b[32m    341\u001b[39m     logs_loop = tc.create_task(\n\u001b[32m    342\u001b[39m         get_app_logs_loop(client, output_mgr, app_id=running_app.app_id, app_logs_url=running_app.app_logs_url)\n\u001b[32m    343\u001b[39m     )\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    346\u001b[39m     \u001b[38;5;66;03m# Create all members\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m _create_all_objects(client, running_app, app._functions, app._classes, environment_name)\n\u001b[32m    349\u001b[39m     \u001b[38;5;66;03m# Publish the app\u001b[39;00m\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m _publish_app(client, running_app, app_state, app._functions, app._classes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/modal/runner.py:180\u001b[39m, in \u001b[36m_create_all_objects\u001b[39m\u001b[34m(client, running_app, functions, classes, environment_name)\u001b[39m\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    178\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected object \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj.object_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m TaskContext.gather(*(_load(tag, obj) \u001b[38;5;28;01mfor\u001b[39;00m tag, obj \u001b[38;5;129;01min\u001b[39;00m indexed_objects.items()))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/modal/_utils/async_utils.py:252\u001b[39m, in \u001b[36mTaskContext.gather\u001b[39m\u001b[34m(*coros)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Wait for a sequence of coroutines to finish, concurrently.\u001b[39;00m\n\u001b[32m    224\u001b[39m \n\u001b[32m    225\u001b[39m \u001b[33;03mThis is similar to `asyncio.gather()`, but it uses TaskContext to cancel all remaining tasks\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    249\u001b[39m \u001b[33;03m```\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m TaskContext() \u001b[38;5;28;01mas\u001b[39;00m tc:\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     results = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*(tc.create_task(coro) \u001b[38;5;28;01mfor\u001b[39;00m coro \u001b[38;5;129;01min\u001b[39;00m coros))\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/modal/runner.py:172\u001b[39m, in \u001b[36m_create_all_objects.<locals>._load\u001b[39m\u001b[34m(tag, obj)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_load\u001b[39m(tag, obj):\n\u001b[32m    171\u001b[39m     existing_object_id = tag_to_object_id.get(tag)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m resolver.load(obj, existing_object_id)\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _Function._is_id_type(obj.object_id):\n\u001b[32m    174\u001b[39m         running_app.function_ids[tag] = obj.object_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/modal/_resolver.py:174\u001b[39m, in \u001b[36mResolver.load\u001b[39m\u001b[34m(self, obj, existing_object_id)\u001b[39m\n\u001b[32m    171\u001b[39m         \u001b[38;5;28mself\u001b[39m._deduplication_cache[deduplication_key] = cached_future\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# TODO(elias): print original exception/trace rather than the Resolver-internal trace\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m cached_future\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/modal/_resolver.py:142\u001b[39m, in \u001b[36mResolver.load.<locals>.loader\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloader\u001b[39m():\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# Wait for all its dependencies\u001b[39;00m\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# TODO(erikbern): do we need existing_object_id for those?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m TaskContext.gather(*[\u001b[38;5;28mself\u001b[39m.load(dep) \u001b[38;5;28;01mfor\u001b[39;00m dep \u001b[38;5;129;01min\u001b[39;00m obj.deps()])\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# Load the object itself\u001b[39;00m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj._load:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/modal/_resolver.py:142\u001b[39m, in \u001b[36mResolver.load.<locals>.loader\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloader\u001b[39m():\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# Wait for all its dependencies\u001b[39;00m\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# TODO(erikbern): do we need existing_object_id for those?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m TaskContext.gather(*[\u001b[38;5;28mself\u001b[39m.load(dep) \u001b[38;5;28;01mfor\u001b[39;00m dep \u001b[38;5;129;01min\u001b[39;00m obj.deps()])\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# Load the object itself\u001b[39;00m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj._load:\n",
      "    \u001b[31m[... skipping similar frames: Resolver.load.<locals>.loader at line 142 (2 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/modal/_resolver.py:142\u001b[39m, in \u001b[36mResolver.load.<locals>.loader\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloader\u001b[39m():\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# Wait for all its dependencies\u001b[39;00m\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# TODO(erikbern): do we need existing_object_id for those?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m TaskContext.gather(*[\u001b[38;5;28mself\u001b[39m.load(dep) \u001b[38;5;28;01mfor\u001b[39;00m dep \u001b[38;5;129;01min\u001b[39;00m obj.deps()])\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# Load the object itself\u001b[39;00m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj._load:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/modal/_utils/async_utils.py:252\u001b[39m, in \u001b[36mTaskContext.gather\u001b[39m\u001b[34m(*coros)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Wait for a sequence of coroutines to finish, concurrently.\u001b[39;00m\n\u001b[32m    224\u001b[39m \n\u001b[32m    225\u001b[39m \u001b[33;03mThis is similar to `asyncio.gather()`, but it uses TaskContext to cancel all remaining tasks\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    249\u001b[39m \u001b[33;03m```\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m TaskContext() \u001b[38;5;28;01mas\u001b[39;00m tc:\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     results = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*(tc.create_task(coro) \u001b[38;5;28;01mfor\u001b[39;00m coro \u001b[38;5;129;01min\u001b[39;00m coros))\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.12/site-packages/modal/_resolver.py:174\u001b[39m, in \u001b[36mResolver.load\u001b[39m\u001b[34m(self, obj, existing_object_id)\u001b[39m\n\u001b[32m    171\u001b[39m         \u001b[38;5;28mself\u001b[39m._deduplication_cache[deduplication_key] = cached_future\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# TODO(elias): print original exception/trace rather than the Resolver-internal trace\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m cached_future\n",
      "\u001b[31mRemoteError\u001b[39m: Image build for im-GhsUxCwkXHCE5fo6Fd59Bg failed with the exception:\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Real Estate Price Prediction API Service\n",
    "Serves the phData ML model with backend demographic data integration\n",
    "\"\"\"\n",
    "\n",
    "from modal import App, Volume, Image\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Optional, Union\n",
    "from fastapi import HTTPException\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from datetime import datetime\n",
    "\n",
    "# =====================================================\n",
    "# Modal App Configuration\n",
    "# =====================================================\n",
    "app = App(\"real-estate-prediction-api\")\n",
    "\n",
    "# Create image with required dependencies\n",
    "base_image = (\n",
    "    Image.debian_slim()\n",
    "    .pip_install([\n",
    "        \"pandas==2.0.3\",\n",
    "        \"numpy==1.24.3\",\n",
    "        \"scikit-learn==1.3.1\",\n",
    "        \"xgboost==1.7.6\",\n",
    "        \"fastapi==0.95.2\",\n",
    "        \"pydantic==1.10.8\",\n",
    "        \"uvicorn==0.22.0\",\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Volume for model and data persistence\n",
    "volume = Volume.from_name(\"sr-hybrid-app-volume\", create_if_missing=True)\n",
    "\n",
    "# =====================================================\n",
    "# Data Models / Request-Response Schemas\n",
    "# =====================================================\n",
    "\n",
    "class HouseFeatures(BaseModel):\n",
    "    \"\"\"Schema for single house prediction request\"\"\"\n",
    "    bedrooms: int = Field(..., ge=0, le=15, description=\"Number of bedrooms\")\n",
    "    bathrooms: float = Field(..., ge=0, le=10, description=\"Number of bathrooms\")\n",
    "    sqft_living: int = Field(..., gt=0, description=\"Square feet of living space\")\n",
    "    sqft_lot: int = Field(..., gt=0, description=\"Square feet of lot\")\n",
    "    floors: float = Field(..., ge=1, le=4, description=\"Number of floors\")\n",
    "    waterfront: int = Field(..., ge=0, le=1, description=\"Waterfront property (0/1)\")\n",
    "    view: int = Field(..., ge=0, le=4, description=\"View quality (0-4)\")\n",
    "    condition: int = Field(..., ge=1, le=5, description=\"Condition of house (1-5)\")\n",
    "    grade: int = Field(..., ge=1, le=13, description=\"Grade of house (1-13)\")\n",
    "    sqft_above: int = Field(..., ge=0, description=\"Square feet above ground\")\n",
    "    sqft_basement: int = Field(..., ge=0, description=\"Square feet of basement\")\n",
    "    yr_built: int = Field(..., ge=1900, le=2025, description=\"Year built\")\n",
    "    yr_renovated: int = Field(..., ge=0, le=2025, description=\"Year renovated (0 if never)\")\n",
    "    zipcode: int = Field(..., description=\"Zipcode\")\n",
    "    lat: float = Field(..., ge=47.0, le=48.0, description=\"Latitude\")\n",
    "    long: float = Field(..., ge=-123.0, le=-121.0, description=\"Longitude\")\n",
    "    sqft_living15: int = Field(..., gt=0, description=\"Living space of nearest 15 neighbors\")\n",
    "    sqft_lot15: int = Field(..., gt=0, description=\"Lot size of nearest 15 neighbors\")\n",
    "    \n",
    "    @validator('yr_renovated')\n",
    "    def validate_renovation_year(cls, v, values):\n",
    "        \"\"\"Ensure renovation year is after build year if renovated\"\"\"\n",
    "        if v > 0 and 'yr_built' in values and v < values['yr_built']:\n",
    "            raise ValueError('Renovation year must be after build year')\n",
    "        return v\n",
    "\n",
    "class BatchPredictionRequest(BaseModel):\n",
    "    \"\"\"Schema for batch prediction request\"\"\"\n",
    "    houses: List[HouseFeatures]\n",
    "\n",
    "class PredictionResponse(BaseModel):\n",
    "    \"\"\"Schema for single prediction response\"\"\"\n",
    "    predicted_price: float\n",
    "    confidence_interval: Optional[Dict[str, float]] = None\n",
    "    zipcode: int\n",
    "    has_demographics: bool\n",
    "    model_version: str\n",
    "    timestamp: str\n",
    "\n",
    "class BatchPredictionResponse(BaseModel):\n",
    "    \"\"\"Schema for batch prediction response\"\"\"\n",
    "    predictions: List[PredictionResponse]\n",
    "    total_houses: int\n",
    "    houses_with_demographics: int\n",
    "    model_version: str\n",
    "    timestamp: str\n",
    "\n",
    "class ModelInfoResponse(BaseModel):\n",
    "    \"\"\"Schema for model info response\"\"\"\n",
    "    model_version: str\n",
    "    expected_features: Dict[str, List[str]]\n",
    "    total_features_required: int\n",
    "    available_zipcodes: int\n",
    "    last_updated: str\n",
    "\n",
    "# =====================================================\n",
    "# Model and Data Management Class\n",
    "# =====================================================\n",
    "\n",
    "class ModelService:\n",
    "    \"\"\"Handles model loading, data preprocessing, and predictions\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.demographics_df = None\n",
    "        self.model_features = None\n",
    "        self.model_version = \"v1.0.0\"\n",
    "        self.model_expected = [\n",
    "            'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
    "            'sqft_above', 'sqft_basement',\n",
    "            'ppltn_qty', 'urbn_ppltn_qty', 'sbrbn_ppltn_qty', 'farm_ppltn_qty', 'non_farm_qty',\n",
    "            'medn_hshld_incm_amt', 'medn_incm_per_prsn_amt', 'hous_val_amt',\n",
    "            'edctn_less_than_9_qty', 'edctn_9_12_qty', 'edctn_high_schl_qty', 'edctn_some_clg_qty',\n",
    "            'edctn_assoc_dgre_qty', 'edctn_bchlr_dgre_qty', 'edctn_prfsnl_qty',\n",
    "            'per_urbn', 'per_sbrbn', 'per_farm', 'per_non_farm',\n",
    "            'per_less_than_9', 'per_9_to_12', 'per_hsd', 'per_some_clg',\n",
    "            'per_assoc', 'per_bchlr', 'per_prfsnl'\n",
    "        ]\n",
    "        \n",
    "    def load_model(self, model_path: str = \"/data/model/model.pkl\") -> bool:\n",
    "        \"\"\"Load the trained model from pickle file\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(model_path):\n",
    "                print(f\"Loading model from {model_path}\")\n",
    "                with open(model_path, 'rb') as f:\n",
    "                    self.model = pickle.load(f)\n",
    "                \n",
    "                # Try to load model features if available\n",
    "                features_path = model_path.replace('model.pkl', 'model_features.json')\n",
    "                if os.path.exists(features_path):\n",
    "                    with open(features_path, 'r') as f:\n",
    "                        self.model_features = json.load(f)\n",
    "                \n",
    "                print(\"Model loaded successfully\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"Model file not found at {model_path}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def load_demographics(self, demographics_path: str = \"/data/data/zipcode_demographics.csv\") -> bool:\n",
    "        \"\"\"Load and cache demographics data\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(demographics_path):\n",
    "                print(f\"Loading demographics from {demographics_path}\")\n",
    "                self.demographics_df = pd.read_csv(demographics_path)\n",
    "                # Convert zipcode to string to handle potential leading zeros\n",
    "                self.demographics_df['zipcode'] = self.demographics_df['zipcode'].astype(str)\n",
    "                \n",
    "                # Create a lookup dictionary for faster access\n",
    "                self.demographics_lookup = self.demographics_df.set_index('zipcode').to_dict('index')\n",
    "                \n",
    "                print(f\"Demographics loaded: {len(self.demographics_df)} zipcodes\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"Demographics file not found at {demographics_path}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading demographics: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def merge_with_demographics(self, house_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Merge house features with demographic data\"\"\"\n",
    "        # Convert zipcode to string for matching\n",
    "        house_df['zipcode'] = house_df['zipcode'].astype(str)\n",
    "        \n",
    "        # Merge with demographics\n",
    "        merged_df = house_df.merge(self.demographics_df, on='zipcode', how='left')\n",
    "        \n",
    "        # Handle missing demographics (zipcodes not in demographics data)\n",
    "        if merged_df.isnull().any().any():\n",
    "            # Fill missing demographic features with median values\n",
    "            demographic_cols = [col for col in self.demographics_df.columns if col != 'zipcode']\n",
    "            for col in demographic_cols:\n",
    "                if col in merged_df.columns:\n",
    "                    median_val = self.demographics_df[col].median()\n",
    "                    merged_df[col].fillna(median_val, inplace=True)\n",
    "                    \n",
    "        return merged_df\n",
    "    \n",
    "    def prepare_features(self, merged_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Select and order features as expected by the model\"\"\"\n",
    "        # Select only the features the model expects\n",
    "        inference_df = merged_df[self.model_expected].copy()\n",
    "        \n",
    "        # Ensure all features are numeric\n",
    "        for col in inference_df.columns:\n",
    "            inference_df[col] = pd.to_numeric(inference_df[col], errors='coerce')\n",
    "        \n",
    "        # Handle any remaining NaN values\n",
    "        inference_df.fillna(0, inplace=True)\n",
    "        \n",
    "        return inference_df\n",
    "    \n",
    "    def predict_single(self, house_features: dict) -> dict:\n",
    "        \"\"\"Make prediction for a single house\"\"\"\n",
    "        # Convert to DataFrame\n",
    "        house_df = pd.DataFrame([house_features])\n",
    "        \n",
    "        # Store original zipcode for response\n",
    "        original_zipcode = house_features['zipcode']\n",
    "        \n",
    "        # Merge with demographics\n",
    "        merged_df = self.merge_with_demographics(house_df)\n",
    "        \n",
    "        # Check if demographics were found\n",
    "        has_demographics = str(original_zipcode) in self.demographics_lookup\n",
    "        \n",
    "        # Prepare features\n",
    "        inference_df = self.prepare_features(merged_df)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = self.model.predict(inference_df)[0]\n",
    "        \n",
    "        # Calculate confidence interval (simplified - you can use model-specific methods)\n",
    "        # For XGBoost, you might use prediction intervals or quantile regression\n",
    "        confidence_interval = {\n",
    "            \"lower_bound\": float(prediction * 0.9),  # Simplified 10% interval\n",
    "            \"upper_bound\": float(prediction * 1.1)\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            \"predicted_price\": float(prediction),\n",
    "            \"confidence_interval\": confidence_interval,\n",
    "            \"zipcode\": original_zipcode,\n",
    "            \"has_demographics\": has_demographics,\n",
    "            \"model_version\": self.model_version,\n",
    "            \"timestamp\": datetime.utcnow().isoformat()\n",
    "        }\n",
    "    \n",
    "    def predict_batch(self, houses: List[dict]) -> dict:\n",
    "        \"\"\"Make predictions for multiple houses\"\"\"\n",
    "        # Convert to DataFrame\n",
    "        houses_df = pd.DataFrame(houses)\n",
    "        \n",
    "        # Store original zipcodes\n",
    "        original_zipcodes = houses_df['zipcode'].tolist()\n",
    "        \n",
    "        # Merge with demographics\n",
    "        merged_df = self.merge_with_demographics(houses_df)\n",
    "        \n",
    "        # Check demographics availability\n",
    "        houses_with_demographics = sum(\n",
    "            1 for zipcode in original_zipcodes \n",
    "            if str(zipcode) in self.demographics_lookup\n",
    "        )\n",
    "        \n",
    "        # Prepare features\n",
    "        inference_df = self.prepare_features(merged_df)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = self.model.predict(inference_df)\n",
    "        \n",
    "        # Build response\n",
    "        prediction_responses = []\n",
    "        for i, (prediction, zipcode) in enumerate(zip(predictions, original_zipcodes)):\n",
    "            prediction_responses.append({\n",
    "                \"predicted_price\": float(prediction),\n",
    "                \"confidence_interval\": {\n",
    "                    \"lower_bound\": float(prediction * 0.9),\n",
    "                    \"upper_bound\": float(prediction * 1.1)\n",
    "                },\n",
    "                \"zipcode\": zipcode,\n",
    "                \"has_demographics\": str(zipcode) in self.demographics_lookup,\n",
    "                \"model_version\": self.model_version,\n",
    "                \"timestamp\": datetime.utcnow().isoformat()\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            \"predictions\": prediction_responses,\n",
    "            \"total_houses\": len(houses),\n",
    "            \"houses_with_demographics\": houses_with_demographics,\n",
    "            \"model_version\": self.model_version,\n",
    "            \"timestamp\": datetime.utcnow().isoformat()\n",
    "        }\n",
    "\n",
    "# =====================================================\n",
    "# API Endpoints\n",
    "# =====================================================\n",
    "\n",
    "# Initialize model service (will be done once when container starts)\n",
    "model_service = ModelService()\n",
    "\n",
    "@app.function(\n",
    "    image=base_image,\n",
    "    volumes={\"/data\": volume},\n",
    "    container_idle_timeout=300,  # Keep warm for 5 minutes\n",
    "    memory=2048,  # 2GB memory\n",
    ")\n",
    "@modal.fastapi_endpoint(method=\"GET\")\n",
    "def health():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"service\": \"real-estate-prediction-api\",\n",
    "        \"model_loaded\": model_service.model is not None,\n",
    "        \"demographics_loaded\": model_service.demographics_df is not None,\n",
    "        \"timestamp\": datetime.utcnow().isoformat()\n",
    "    }\n",
    "\n",
    "@app.function(\n",
    "    image=base_image,\n",
    "    volumes={\"/data\": volume},\n",
    "    container_idle_timeout=300,\n",
    "    memory=2048,\n",
    ")\n",
    "@modal.fastapi_endpoint(method=\"POST\")\n",
    "def predict(house: HouseFeatures):\n",
    "    \"\"\"Single house price prediction endpoint\"\"\"\n",
    "    # Initialize model if not loaded\n",
    "    if model_service.model is None:\n",
    "        if not model_service.load_model():\n",
    "            raise HTTPException(status_code=500, detail=\"Model not available\")\n",
    "    \n",
    "    if model_service.demographics_df is None:\n",
    "        if not model_service.load_demographics():\n",
    "            raise HTTPException(status_code=500, detail=\"Demographics data not available\")\n",
    "    \n",
    "    try:\n",
    "        # Convert Pydantic model to dict\n",
    "        house_dict = house.dict()\n",
    "        \n",
    "        # Make prediction\n",
    "        result = model_service.predict_single(house_dict)\n",
    "        \n",
    "        return PredictionResponse(**result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Prediction error: {str(e)}\")\n",
    "\n",
    "@app.function(\n",
    "    image=base_image,\n",
    "    volumes={\"/data\": volume},\n",
    "    container_idle_timeout=300,\n",
    "    memory=2048,\n",
    ")\n",
    "@modal.fastapi_endpoint(method=\"POST\")\n",
    "def predict_batch(request: BatchPredictionRequest):\n",
    "    \"\"\"Batch prediction endpoint for multiple houses\"\"\"\n",
    "    # Initialize model if not loaded\n",
    "    if model_service.model is None:\n",
    "        if not model_service.load_model():\n",
    "            raise HTTPException(status_code=500, detail=\"Model not available\")\n",
    "    \n",
    "    if model_service.demographics_df is None:\n",
    "        if not model_service.load_demographics():\n",
    "            raise HTTPException(status_code=500, detail=\"Demographics data not available\")\n",
    "    \n",
    "    try:\n",
    "        # Convert Pydantic models to dicts\n",
    "        houses_dicts = [house.dict() for house in request.houses]\n",
    "        \n",
    "        # Make predictions\n",
    "        result = model_service.predict_batch(houses_dicts)\n",
    "        \n",
    "        return BatchPredictionResponse(**result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Batch prediction error: {str(e)}\")\n",
    "\n",
    "@app.function(\n",
    "    image=base_image,\n",
    "    volumes={\"/data\": volume},\n",
    "    container_idle_timeout=300,\n",
    "    memory=2048,\n",
    ")\n",
    "@modal.fastapi_endpoint(method=\"GET\")\n",
    "def model_info():\n",
    "    \"\"\"Get model information and expected features\"\"\"\n",
    "    # Initialize if needed\n",
    "    if model_service.demographics_df is None:\n",
    "        model_service.load_demographics()\n",
    "    \n",
    "    house_features = [\n",
    "        'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
    "        'waterfront', 'view', 'condition', 'grade', 'sqft_above', \n",
    "        'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', \n",
    "        'lat', 'long', 'sqft_living15', 'sqft_lot15'\n",
    "    ]\n",
    "    \n",
    "    demographic_features = [\n",
    "        'ppltn_qty', 'urbn_ppltn_qty', 'sbrbn_ppltn_qty', 'farm_ppltn_qty', 'non_farm_qty',\n",
    "        'medn_hshld_incm_amt', 'medn_incm_per_prsn_amt', 'hous_val_amt',\n",
    "        'edctn_less_than_9_qty', 'edctn_9_12_qty', 'edctn_high_schl_qty', \n",
    "        'edctn_some_clg_qty', 'edctn_assoc_dgre_qty', 'edctn_bchlr_dgre_qty', \n",
    "        'edctn_prfsnl_qty', 'per_urbn', 'per_sbrbn', 'per_farm', 'per_non_farm',\n",
    "        'per_less_than_9', 'per_9_to_12', 'per_hsd', 'per_some_clg',\n",
    "        'per_assoc', 'per_bchlr', 'per_prfsnl'\n",
    "    ]\n",
    "    \n",
    "    return ModelInfoResponse(\n",
    "        model_version=model_service.model_version,\n",
    "        expected_features={\n",
    "            \"input_features\": house_features,\n",
    "            \"demographic_features\": demographic_features,\n",
    "            \"model_features\": model_service.model_expected\n",
    "        },\n",
    "        total_features_required=len(model_service.model_expected),\n",
    "        available_zipcodes=len(model_service.demographics_df) if model_service.demographics_df is not None else 0,\n",
    "        last_updated=datetime.utcnow().isoformat()\n",
    "    )\n",
    "\n",
    "@app.function(\n",
    "    image=base_image,\n",
    "    volumes={\"/data\": volume},\n",
    "    container_idle_timeout=300,\n",
    "    memory=2048,\n",
    ")\n",
    "@modal.fastapi_endpoint(method=\"GET\")\n",
    "def available_zipcodes():\n",
    "    \"\"\"Get list of zipcodes with demographic data available\"\"\"\n",
    "    if model_service.demographics_df is None:\n",
    "        if not model_service.load_demographics():\n",
    "            raise HTTPException(status_code=500, detail=\"Demographics data not available\")\n",
    "    \n",
    "    zipcodes = model_service.demographics_df['zipcode'].unique().tolist()\n",
    "    return {\n",
    "        \"zipcodes\": sorted(zipcodes),\n",
    "        \"total\": len(zipcodes)\n",
    "    }\n",
    "\n",
    "# =====================================================\n",
    "# Local Entry Point for Deployment\n",
    "# =====================================================\n",
    "\n",
    "@app.local_entrypoint()\n",
    "def main():\n",
    "    \"\"\"Deploy the API and pre-load model/data\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"Deploying Real Estate Prediction API...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Pre-warm the service by loading model and data\n",
    "    print(\"\\nPre-loading model and data...\")\n",
    "    \n",
    "    # Trigger model loading\n",
    "    with app.run():\n",
    "        health_status = health.remote()\n",
    "        print(f\"\\nHealth check: {health_status}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"API Deployment Complete!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nEndpoints available:\")\n",
    "    print(\"- Health Check: GET  /health\")\n",
    "    print(\"- Single Prediction: POST /predict\")\n",
    "    print(\"- Batch Prediction: POST /predict_batch\")\n",
    "    print(\"- Model Info: GET /model_info\")\n",
    "    print(\"- Available Zipcodes: GET /available_zipcodes\")\n",
    "    print(\"\\nYour API endpoints will be available at:\")\n",
    "    print(\"https://[your-username]--real-estate-prediction-api-[endpoint].modal.run\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad165580-2ee1-47c2-b5ea-3236e5103e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48dc0f50-119f-4176-adfd-4d8c8dd42c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create app definition\n",
    "app = modal.App(\"sr-hybrid-upload-app\")\n",
    "\n",
    "# Define base image with all dependencies\n",
    "base_image = (modal.Image.debian_slim()\n",
    "        .pip_install(\"fastapi\",\"uvicorn\",\"scikit-learn\",\"pandas\",\"numpy\",\"joblib\",\"dash\"))\n",
    "\n",
    "# Create the fastai image by extending the base image\n",
    "fastai_image = (base_image\n",
    "               .pip_install([\"fastai\", \"torch\"]))\n",
    "\n",
    "# Create volume to access data\n",
    "data_volume = modal.Volume.from_name(\"sr-hybrid-app-volume\")\n",
    "\n",
    "# Simple health endpoint\n",
    "@app.function(image=base_image)\n",
    "@modal.fastapi_endpoint(method=\"GET\")\n",
    "def health():\n",
    "   \"\"\"Health check endpoint to verify the API is running\"\"\"\n",
    "   return {\"status\": \"healthy\", \"service\": \"sr-hybrid-upload-api\"}\n",
    "\n",
    "# Function to load or train a model\n",
    "@app.function(image=fastai_image, volumes={\"/data\": data_volume})\n",
    "def serve_model():\n",
    "   \"\"\"Load or train an XGBoost model\"\"\"\n",
    "   import xgboost as xgb\n",
    "   from fastai.tabular.all import add_datepart, TabularPandas, cont_cat_split\n",
    "   from fastai.tabular.all import Categorify, FillMissing, Normalize, CategoryBlock, RandomSplitter, range_of\n",
    "   from pathlib import Path\n",
    "   import pickle\n",
    "   import os\n",
    "   import bentoml\n",
    "   \n",
    "   # Model tag used in train.py\n",
    "   model_tag = \"sr_v1\"\n",
    "   \n",
    "   # Create a path to save the model for future use\n",
    "   model_path = \"./model/model.pkl\"\n",
    "   \n",
    "   try:\n",
    "       #\n",
    "       # Second attempt: Try loading from pickle\n",
    "       if os.path.exists(model_path):\n",
    "           print(f\"Loading existing model from pickle at {model_path}\")\n",
    "           with open(model_path, 'rb') as f:\n",
    "               model = pickle.load(f)\n",
    "           return model\n",
    "       \n",
    "       \n",
    "   except Exception as e:\n",
    "       import traceback\n",
    "       print(f\"Error loading/training model: {str(e)}\")\n",
    "       print(traceback.format_exc())\n",
    "       raise\n",
    "\n",
    "\n",
    "## new predict_csv function with preprocessing step\n",
    "# CSV upload endpoint with optimized preprocessing\n",
    "# CSV upload endpoint with optimized preprocessing\n",
    "# CSV upload endpoint - with debugging info (commented out)\n",
    "@app.function(image=fastai_image, volumes={\"/data\": data_volume})\n",
    "@modal.fastapi_endpoint(method=\"POST\")\n",
    "async def predict_csv(file: UploadFile = File(...)):\n",
    "    \"\"\"API endpoint for batch predictions from a CSV file using cached preprocessing\"\"\"\n",
    "    import xgboost as xgb\n",
    "    import io\n",
    "    import pickle\n",
    "    import os\n",
    "    import traceback\n",
    "    from fastai.tabular.all import add_datepart, TabularPandas, cont_cat_split\n",
    "    from fastai.tabular.all import Categorify, FillMissing, Normalize, CategoryBlock, RandomSplitter, range_of\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Uncomment for debugging\n",
    "    # response_data = {\"success\": False, \"debug_info\": {}}\n",
    "    \n",
    "    try:\n",
    "        # Debug information\n",
    "        # response_data[\"debug_info\"][\"step\"] = \"Starting prediction process\"\n",
    "        \n",
    "        # First, load or train model\n",
    "        model = serve_model.remote()\n",
    "        # response_data[\"debug_info\"][\"model_loaded\"] = True\n",
    "        \n",
    "        # Read uploaded CSV file content\n",
    "        contents = await file.read()\n",
    "        \n",
    "        # Parse CSV data\n",
    "        try:\n",
    "            test_df = pd.read_csv(io.BytesIO(contents))\n",
    "            # response_data[\"debug_info\"][\"test_columns\"] = test_df.columns.tolist()\n",
    "            # response_data[\"debug_info\"][\"test_shape_before\"] = test_df.shape\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Failed to parse uploaded CSV: {str(e)}\"\n",
    "            }\n",
    "        \n",
    "        \n",
    "        # Load the full training data to ensure proper preprocessing\n",
    "        path = Path('/data/')\n",
    "        test_df = pd.read_csv(path/'future_unseen_examples.csv', index_col='id')\n",
    "        # Make predictions\n",
    "        predictions = model.predict(test_df)\n",
    "        \n",
    "        # Return predictions in the format expected by test_modal_api.py\n",
    "        return predictions.tolist()\n",
    "        \n",
    "        # To return structured response with debug info, use this instead:\n",
    "        # response_data[\"success\"] = True\n",
    "        # response_data[\"predictions\"] = predictions.tolist()\n",
    "        # return response_data\n",
    "            \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": f\"Error processing CSV: {str(e)}\",\n",
    "            \"traceback\": traceback.format_exc()\n",
    "        }\n",
    "\n",
    "\n",
    "@app.local_entrypoint()\n",
    "def main():\n",
    "   \"\"\"Local entrypoint for testing the API\"\"\"\n",
    "   print(\"Starting sticker-sales-api...\")\n",
    "   \n",
    "   # Pre-load the model to ensure it exists\n",
    "   print(\"Preparing model...\")\n",
    "   serve_model.remote()\n",
    "   print(\"Model preparation complete!\")\n",
    "   \n",
    "   print(\"\\nAPI is ready for use at:\")\n",
    "   print(\"- Health check: https://flexible-functions-ai--sticker-sales-api-health.modal.run\")\n",
    "   print(\"- CSV predictions: https://flexible-functions-ai--sticker-sales-api-predict-csv.modal.run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc564459-73c4-4379-80b8-7dc5f80bb4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
